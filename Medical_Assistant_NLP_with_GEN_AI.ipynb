{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3CNz35ia6Bz3"
      },
      "source": [
        "## Problem Statement"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CkRbhMJH6Bz3"
      },
      "source": [
        "### Business Context"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3PBm5xaj6Bz3"
      },
      "source": [
        "The healthcare industry is rapidly evolving, with professionals facing increasing challenges in managing vast volumes of medical data while delivering accurate and timely diagnoses. The need for quick access to comprehensive, reliable, and up-to-date medical knowledge is critical for improving patient outcomes and ensuring informed decision-making in a fast-paced environment.\n",
        "\n",
        "Healthcare professionals often encounter information overload, struggling to sift through extensive research and data to create accurate diagnoses and treatment plans. This challenge is amplified by the need for efficiency, particularly in emergencies, where time-sensitive decisions are vital. Furthermore, access to trusted, current medical information from renowned manuals and research papers is essential for maintaining high standards of care.\n",
        "\n",
        "To address these challenges, healthcare centers can focus on integrating systems that streamline access to medical knowledge, provide tools to support quick decision-making, and enhance efficiency. Leveraging centralized knowledge platforms and ensuring healthcare providers have continuous access to reliable resources can significantly improve patient care and operational effectiveness."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1xDPsqvO6Bz5"
      },
      "source": [
        "**Common Questions to Answer**\n",
        "\n",
        "**1. Diagnostic Assistance**: \"What are the common symptoms and treatments for pulmonary embolism?\"\n",
        "\n",
        "**2. Drug Information**: \"Can you provide the trade names of medications used for treating hypertension?\"\n",
        "\n",
        "**3. Treatment Plans**: \"What are the first-line options and alternatives for managing rheumatoid arthritis?\"\n",
        "\n",
        "**4. Specialty Knowledge**: \"What are the diagnostic steps for suspected endocrine disorders?\"\n",
        "\n",
        "**5. Critical Care Protocols**: \"What is the protocol for managing sepsis in a critical care unit?\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CARPKFwm6Bz4"
      },
      "source": [
        "### Objective"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dOElOEXq6Bz4"
      },
      "source": [
        "As an AI specialist, your task is to develop a RAG-based AI solution using renowned medical manuals to address healthcare challenges. The objective is to **understand** issues like information overload, **apply** AI techniques to streamline decision-making, **analyze** its impact on diagnostics and patient outcomes, **evaluate** its potential to standardize care practices, and **create** a functional prototype demonstrating its feasibility and effectiveness."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "by9EvAnkSpZf"
      },
      "source": [
        "### Data Description"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jw5LievCSru2"
      },
      "source": [
        "The **Merck Manuals** are medical references published by the American pharmaceutical company Merck & Co., that cover a wide range of medical topics, including disorders, tests, diagnoses, and drugs. The manuals have been published since 1899, when Merck & Co. was still a subsidiary of the German company Merck.\n",
        "\n",
        "The manual is provided as a PDF with over 4,000 pages divided into 23 sections."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lnwETBOE6Bz5"
      },
      "source": [
        "## Installing and Importing Necessary Libraries and Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q4GgLhZhUM4V",
        "outputId": "8fce7663-233a-4a4f-fbfc-60c90aca0827"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting llama-cpp-python\n",
            "  Downloading llama_cpp_python-0.3.11.tar.gz (79.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.1/79.1 MB\u001b[0m \u001b[31m32.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from llama-cpp-python) (4.14.0)\n",
            "Requirement already satisfied: numpy>=1.20.0 in /usr/local/lib/python3.11/dist-packages (from llama-cpp-python) (2.0.2)\n",
            "Collecting diskcache>=5.6.1 (from llama-cpp-python)\n",
            "  Downloading diskcache-5.6.3-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: jinja2>=2.11.3 in /usr/local/lib/python3.11/dist-packages (from llama-cpp-python) (3.1.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2>=2.11.3->llama-cpp-python) (3.0.2)\n",
            "Downloading diskcache-5.6.3-py3-none-any.whl (45 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.5/45.5 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: llama-cpp-python\n",
            "  Building wheel for llama-cpp-python (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for llama-cpp-python: filename=llama_cpp_python-0.3.11-cp311-cp311-linux_x86_64.whl size=4122682 sha256=2cdb7628179e5c7da6022165f9cd430a095c74727432e41b83f29daeca9689e5\n",
            "  Stored in directory: /root/.cache/pip/wheels/1a/65/e9/3bd26ec174c6e148cce8a3876d7ed32652e3508ebe262c197a\n",
            "Successfully built llama-cpp-python\n",
            "Installing collected packages: diskcache, llama-cpp-python\n",
            "Successfully installed diskcache-5.6.3 llama-cpp-python-0.3.11\n"
          ]
        }
      ],
      "source": [
        "# Installation for GPU llama-cpp-python\n",
        "# uncomment and run the following code in case GPU is being used\n",
        "!CMAKE_ARGS=\"-DLLAMA_CUBLAS=on\" FORCE_CMAKE=1\n",
        "!pip install llama-cpp-python\n",
        "\n",
        "# Installation for CPU llama-cpp-python\n",
        "# uncomment and run the following code in case GPU is not being used\n",
        "# !CMAKE_ARGS=\"-DLLAMA_CUBLAS=off\" FORCE_CMAKE=1 pip install llama-cpp-python==0.1.85 --force-reinstall --no-cache-dir -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5rsoQIOowCTS",
        "outputId": "4aacbabb-e211-471f-b2e3-df691af0b487"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install numpy\n",
        "!pip install pandas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0VOckDVkWGei",
        "outputId": "645a3f3d-ac70-418b-ccea-ad0c0836dcc2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.11/dist-packages (0.33.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (2025.3.2)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (4.14.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (1.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub) (2025.6.15)\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.11/dist-packages (0.9.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from tiktoken) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (2025.6.15)\n",
            "Collecting pymupdf\n",
            "  Downloading pymupdf-1.26.3-cp39-abi3-manylinux_2_28_x86_64.whl.metadata (3.4 kB)\n",
            "Downloading pymupdf-1.26.3-cp39-abi3-manylinux_2_28_x86_64.whl (24.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.1/24.1 MB\u001b[0m \u001b[31m77.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pymupdf\n",
            "Successfully installed pymupdf-1.26.3\n",
            "Requirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.3.26)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.66 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.67)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.8)\n",
            "Requirement already satisfied: langsmith>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.4.4)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.11.7)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.0.41)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.66->langchain) (8.5.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.66->langchain) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.66->langchain) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.66->langchain) (4.14.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.17->langchain) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.17->langchain) (3.10.18)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.17->langchain) (0.23.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2025.6.15)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.3)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (4.9.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.66->langchain) (3.0.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (1.3.1)\n",
            "Collecting langchain-community\n",
            "  Downloading langchain_community-0.3.27-py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.66 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.3.67)\n",
            "Requirement already satisfied: langchain<1.0.0,>=0.3.26 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.3.26)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.0.41)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (6.0.2)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (3.11.15)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (8.5.0)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain-community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain-community)\n",
            "  Downloading pydantic_settings-2.10.1-py3-none-any.whl.metadata (3.4 kB)\n",
            "Requirement already satisfied: langsmith>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.4.4)\n",
            "Collecting httpx-sse<1.0.0,>=0.4.0 (from langchain-community)\n",
            "  Downloading httpx_sse-0.4.1-py3-none-any.whl.metadata (9.4 kB)\n",
            "Requirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.6.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.20.1)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /usr/local/lib/python3.11/dist-packages (from langchain<1.0.0,>=0.3.26->langchain-community) (0.3.8)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain<1.0.0,>=0.3.26->langchain-community) (2.11.7)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.66->langchain-community) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.66->langchain-community) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.66->langchain-community) (4.14.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.125->langchain-community) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.125->langchain-community) (3.10.18)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.125->langchain-community) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.125->langchain-community) (0.23.0)\n",
            "Collecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.4.0->langchain-community)\n",
            "  Downloading python_dotenv-1.1.1-py3-none-any.whl.metadata (24 kB)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (2025.6.15)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain-community) (3.2.3)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.1.125->langchain-community) (4.9.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.1.125->langchain-community) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.1.125->langchain-community) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.66->langchain-community) (3.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.26->langchain-community) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.26->langchain-community) (2.33.2)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.1.125->langchain-community) (1.3.1)\n",
            "Downloading langchain_community-0.3.27-py3-none-any.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m35.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading httpx_sse-0.4.1-py3-none-any.whl (8.1 kB)\n",
            "Downloading pydantic_settings-2.10.1-py3-none-any.whl (45 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.2/45.2 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.1.1-py3-none-any.whl (20 kB)\n",
            "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
            "Installing collected packages: python-dotenv, mypy-extensions, marshmallow, httpx-sse, typing-inspect, pydantic-settings, dataclasses-json, langchain-community\n",
            "Successfully installed dataclasses-json-0.6.7 httpx-sse-0.4.1 langchain-community-0.3.27 marshmallow-3.26.1 mypy-extensions-1.1.0 pydantic-settings-2.10.1 python-dotenv-1.1.1 typing-inspect-0.9.0\n",
            "Collecting chromadb\n",
            "  Downloading chromadb-1.0.15-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.0 kB)\n",
            "Requirement already satisfied: build>=1.0.3 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.2.2.post1)\n",
            "Requirement already satisfied: pydantic>=1.9 in /usr/local/lib/python3.11/dist-packages (from chromadb) (2.11.7)\n",
            "Collecting pybase64>=1.4.1 (from chromadb)\n",
            "  Downloading pybase64-1.4.1-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.4 kB)\n",
            "Requirement already satisfied: uvicorn>=0.18.3 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.35.0)\n",
            "Requirement already satisfied: numpy>=1.22.5 in /usr/local/lib/python3.11/dist-packages (from chromadb) (2.0.2)\n",
            "Collecting posthog<6.0.0,>=2.4.0 (from chromadb)\n",
            "  Downloading posthog-5.4.0-py3-none-any.whl.metadata (5.7 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (4.14.0)\n",
            "Collecting onnxruntime>=1.14.1 (from chromadb)\n",
            "  Downloading onnxruntime-1.22.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.5 kB)\n",
            "Collecting opentelemetry-api>=1.2.0 (from chromadb)\n",
            "  Downloading opentelemetry_api-1.34.1-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.34.1-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting opentelemetry-sdk>=1.2.0 (from chromadb)\n",
            "  Downloading opentelemetry_sdk-1.34.1-py3-none-any.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: tokenizers>=0.13.2 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.21.2)\n",
            "Collecting pypika>=0.48.9 (from chromadb)\n",
            "  Downloading PyPika-0.48.9.tar.gz (67 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (4.67.1)\n",
            "Collecting overrides>=7.3.1 (from chromadb)\n",
            "  Downloading overrides-7.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.11/dist-packages (from chromadb) (6.5.2)\n",
            "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.73.1)\n",
            "Collecting bcrypt>=4.0.1 (from chromadb)\n",
            "  Downloading bcrypt-4.3.0-cp39-abi3-manylinux_2_34_x86_64.whl.metadata (10 kB)\n",
            "Requirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.16.0)\n",
            "Collecting kubernetes>=28.1.0 (from chromadb)\n",
            "  Downloading kubernetes-33.1.0-py2.py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: tenacity>=8.2.3 in /usr/local/lib/python3.11/dist-packages (from chromadb) (8.5.0)\n",
            "Requirement already satisfied: pyyaml>=6.0.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (6.0.2)\n",
            "Collecting mmh3>=4.0.1 (from chromadb)\n",
            "  Downloading mmh3-5.1.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (16 kB)\n",
            "Requirement already satisfied: orjson>=3.9.12 in /usr/local/lib/python3.11/dist-packages (from chromadb) (3.10.18)\n",
            "Requirement already satisfied: httpx>=0.27.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.28.1)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (13.9.4)\n",
            "Requirement already satisfied: jsonschema>=4.19.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (4.24.0)\n",
            "Requirement already satisfied: packaging>=19.1 in /usr/local/lib/python3.11/dist-packages (from build>=1.0.3->chromadb) (24.2)\n",
            "Requirement already satisfied: pyproject_hooks in /usr/local/lib/python3.11/dist-packages (from build>=1.0.3->chromadb) (1.2.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb) (4.9.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb) (2025.6.15)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb) (3.10)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.27.0->chromadb) (0.16.0)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.19.0->chromadb) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.19.0->chromadb) (2025.4.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.19.0->chromadb) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.19.0->chromadb) (0.26.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (1.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.9.0.post0)\n",
            "Requirement already satisfied: google-auth>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.38.0)\n",
            "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (1.8.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.32.3)\n",
            "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.0.0)\n",
            "Requirement already satisfied: oauthlib>=3.2.2 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (3.3.1)\n",
            "Requirement already satisfied: urllib3>=1.24.2 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.4.0)\n",
            "Collecting durationpy>=0.7 (from kubernetes>=28.1.0->chromadb)\n",
            "  Downloading durationpy-0.10-py3-none-any.whl.metadata (340 bytes)\n",
            "Collecting coloredlogs (from onnxruntime>=1.14.1->chromadb)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb) (25.2.10)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb) (5.29.5)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb) (1.13.1)\n",
            "Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-api>=1.2.0->chromadb) (8.7.0)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.52 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.70.0)\n",
            "Collecting opentelemetry-exporter-otlp-proto-common==1.34.1 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_common-1.34.1-py3-none-any.whl.metadata (1.9 kB)\n",
            "Collecting opentelemetry-proto==1.34.1 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
            "  Downloading opentelemetry_proto-1.34.1-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting opentelemetry-semantic-conventions==0.55b1 (from opentelemetry-sdk>=1.2.0->chromadb)\n",
            "  Downloading opentelemetry_semantic_conventions-0.55b1-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting backoff>=1.10.0 (from posthog<6.0.0,>=2.4.0->chromadb)\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: distro>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from posthog<6.0.0,>=2.4.0->chromadb) (1.9.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=1.9->chromadb) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=1.9->chromadb) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=1.9->chromadb) (0.4.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->chromadb) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->chromadb) (2.19.2)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.11/dist-packages (from tokenizers>=0.13.2->chromadb) (0.33.1)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer>=0.9.0->chromadb) (8.2.1)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer>=0.9.0->chromadb) (1.5.4)\n",
            "Collecting httptools>=0.6.3 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading httptools-0.6.4-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: python-dotenv>=0.13 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.1.1)\n",
            "Collecting uvloop>=0.15.1 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading uvloop-0.21.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Collecting watchfiles>=0.13 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading watchfiles-1.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (15.0.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.9.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (2025.3.2)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (1.1.5)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.23.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb) (0.1.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->kubernetes>=28.1.0->chromadb) (3.4.2)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx>=0.27.0->chromadb) (1.3.1)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromadb)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.6.1)\n",
            "Downloading chromadb-1.0.15-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (19.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.5/19.5 MB\u001b[0m \u001b[31m114.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading bcrypt-4.3.0-cp39-abi3-manylinux_2_34_x86_64.whl (284 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m284.2/284.2 kB\u001b[0m \u001b[31m23.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading kubernetes-33.1.0-py2.py3-none-any.whl (1.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m71.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mmh3-5.1.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (101 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.6/101.6 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnxruntime-1.22.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (16.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.4/16.4 MB\u001b[0m \u001b[31m120.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_api-1.34.1-py3-none-any.whl (65 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.8/65.8 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_exporter_otlp_proto_grpc-1.34.1-py3-none-any.whl (18 kB)\n",
            "Downloading opentelemetry_exporter_otlp_proto_common-1.34.1-py3-none-any.whl (18 kB)\n",
            "Downloading opentelemetry_proto-1.34.1-py3-none-any.whl (55 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.7/55.7 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_sdk-1.34.1-py3-none-any.whl (118 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118.5/118.5 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_semantic_conventions-0.55b1-py3-none-any.whl (196 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.2/196.2 kB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading overrides-7.7.0-py3-none-any.whl (17 kB)\n",
            "Downloading posthog-5.4.0-py3-none-any.whl (105 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.4/105.4 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pybase64-1.4.1-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (71 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.2/71.2 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading durationpy-0.10-py3-none-any.whl (3.9 kB)\n",
            "Downloading httptools-0.6.4-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (459 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m459.8/459.8 kB\u001b[0m \u001b[31m37.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading uvloop-0.21.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.0/4.0 MB\u001b[0m \u001b[31m108.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading watchfiles-1.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (453 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m453.1/453.1 kB\u001b[0m \u001b[31m39.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: pypika\n",
            "  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pypika: filename=pypika-0.48.9-py2.py3-none-any.whl size=53803 sha256=98d95aca7661f4fb5621adccba7e15b73d76e195ad95cdea3c4ac66643be3163\n",
            "  Stored in directory: /root/.cache/pip/wheels/a3/01/bd/4c40ceb9d5354160cb186dcc153360f4ab7eb23e2b24daf96d\n",
            "Successfully built pypika\n",
            "Installing collected packages: pypika, durationpy, uvloop, pybase64, overrides, opentelemetry-proto, mmh3, humanfriendly, httptools, bcrypt, backoff, watchfiles, posthog, opentelemetry-exporter-otlp-proto-common, opentelemetry-api, coloredlogs, opentelemetry-semantic-conventions, onnxruntime, kubernetes, opentelemetry-sdk, opentelemetry-exporter-otlp-proto-grpc, chromadb\n",
            "Successfully installed backoff-2.2.1 bcrypt-4.3.0 chromadb-1.0.15 coloredlogs-15.0.1 durationpy-0.10 httptools-0.6.4 humanfriendly-10.0 kubernetes-33.1.0 mmh3-5.1.0 onnxruntime-1.22.0 opentelemetry-api-1.34.1 opentelemetry-exporter-otlp-proto-common-1.34.1 opentelemetry-exporter-otlp-proto-grpc-1.34.1 opentelemetry-proto-1.34.1 opentelemetry-sdk-1.34.1 opentelemetry-semantic-conventions-0.55b1 overrides-7.7.0 posthog-5.4.0 pybase64-1.4.1 pypika-0.48.9 uvloop-0.21.0 watchfiles-1.1.0\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.11/dist-packages (4.1.0)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.53.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.67.1)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (2.6.0+cu124)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.15.3)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (0.33.1)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (11.2.1)\n",
            "Requirement already satisfied: typing_extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.14.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.3.2)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.3)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (1.1.5)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.2)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.5.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2025.6.15)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m126.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m103.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m53.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m43.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m19.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m108.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n"
          ]
        }
      ],
      "source": [
        "# For installing the libraries & downloading models from HF Hub\n",
        "%pip install huggingface_hub\n",
        "%pip install tiktoken\n",
        "%pip install pymupdf\n",
        "%pip install langchain\n",
        "%pip install langchain-community\n",
        "%pip install chromadb\n",
        "%pip install sentence-transformers\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RTY9GN4oWK3g"
      },
      "outputs": [],
      "source": [
        "#Libraries for downloading and loading the llm\n",
        "from huggingface_hub import hf_hub_download\n",
        "from llama_cpp import Llama"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TtZWqj0wFTS1"
      },
      "source": [
        "## Question Answering using LLM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uq1lhM4WFTS2"
      },
      "source": [
        "#### Downloading and Loading the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "referenced_widgets": [
            "0390af2342204727b89674f8073b6a7b",
            "1e3007a584504b23a3be5e32fc630458",
            "cb1de09892634e419c54b3ef21653144",
            "f66d84a88635483b8b9d389df158caca",
            "6a5df697af3a449bb365510218d82550",
            "205f9fe8522941e88ba954024a6a18c8",
            "597325b6091d4416992eb70bdbe4c1a5",
            "db773b60d2ac4ccd8b29af7960124e8b",
            "22093be185744babac4caa06a0312516",
            "dd7d49b2f6e24cf4932c4c99b26a6cad",
            "9b92a2ad19994e16b3f3046a10564870"
          ]
        },
        "id": "dA3XQMWmQLJp",
        "outputId": "dd17ff27-6aa5-4621-aae7-d9b92937155a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "mistral-7b-instruct-v0.2.Q6_K.gguf:   0%|          | 0.00/5.94G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0390af2342204727b89674f8073b6a7b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "llama_model_loader: loaded meta data with 24 key-value pairs and 291 tensors from /root/.cache/huggingface/hub/models--TheBloke--Mistral-7B-Instruct-v0.2-GGUF/snapshots/3a6fbf4a41a1d52e415a4958cde6856d34b2db93/mistral-7b-instruct-v0.2.Q6_K.gguf (version GGUF V3 (latest))\n",
            "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
            "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
            "llama_model_loader: - kv   1:                               general.name str              = mistralai_mistral-7b-instruct-v0.2\n",
            "llama_model_loader: - kv   2:                       llama.context_length u32              = 32768\n",
            "llama_model_loader: - kv   3:                     llama.embedding_length u32              = 4096\n",
            "llama_model_loader: - kv   4:                          llama.block_count u32              = 32\n",
            "llama_model_loader: - kv   5:                  llama.feed_forward_length u32              = 14336\n",
            "llama_model_loader: - kv   6:                 llama.rope.dimension_count u32              = 128\n",
            "llama_model_loader: - kv   7:                 llama.attention.head_count u32              = 32\n",
            "llama_model_loader: - kv   8:              llama.attention.head_count_kv u32              = 8\n",
            "llama_model_loader: - kv   9:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010\n",
            "llama_model_loader: - kv  10:                       llama.rope.freq_base f32              = 1000000.000000\n",
            "llama_model_loader: - kv  11:                          general.file_type u32              = 18\n",
            "llama_model_loader: - kv  12:                       tokenizer.ggml.model str              = llama\n",
            "llama_model_loader: - kv  13:                      tokenizer.ggml.tokens arr[str,32000]   = [\"<unk>\", \"<s>\", \"</s>\", \"<0x00>\", \"<...\n",
            "llama_model_loader: - kv  14:                      tokenizer.ggml.scores arr[f32,32000]   = [0.000000, 0.000000, 0.000000, 0.0000...\n",
            "llama_model_loader: - kv  15:                  tokenizer.ggml.token_type arr[i32,32000]   = [2, 3, 3, 6, 6, 6, 6, 6, 6, 6, 6, 6, ...\n",
            "llama_model_loader: - kv  16:                tokenizer.ggml.bos_token_id u32              = 1\n",
            "llama_model_loader: - kv  17:                tokenizer.ggml.eos_token_id u32              = 2\n",
            "llama_model_loader: - kv  18:            tokenizer.ggml.unknown_token_id u32              = 0\n",
            "llama_model_loader: - kv  19:            tokenizer.ggml.padding_token_id u32              = 0\n",
            "llama_model_loader: - kv  20:               tokenizer.ggml.add_bos_token bool             = true\n",
            "llama_model_loader: - kv  21:               tokenizer.ggml.add_eos_token bool             = false\n",
            "llama_model_loader: - kv  22:                    tokenizer.chat_template str              = {{ bos_token }}{% for message in mess...\n",
            "llama_model_loader: - kv  23:               general.quantization_version u32              = 2\n",
            "llama_model_loader: - type  f32:   65 tensors\n",
            "llama_model_loader: - type q6_K:  226 tensors\n",
            "print_info: file format = GGUF V3 (latest)\n",
            "print_info: file type   = Q6_K\n",
            "print_info: file size   = 5.53 GiB (6.56 BPW) \n",
            "init_tokenizer: initializing tokenizer for type 1\n",
            "load: control token:      2 '</s>' is not marked as EOG\n",
            "load: control token:      1 '<s>' is not marked as EOG\n",
            "load: special_eos_id is not in special_eog_ids - the tokenizer config may be incorrect\n",
            "load: special tokens cache size = 3\n",
            "load: token to piece cache size = 0.1637 MB\n",
            "print_info: arch             = llama\n",
            "print_info: vocab_only       = 0\n",
            "print_info: n_ctx_train      = 32768\n",
            "print_info: n_embd           = 4096\n",
            "print_info: n_layer          = 32\n",
            "print_info: n_head           = 32\n",
            "print_info: n_head_kv        = 8\n",
            "print_info: n_rot            = 128\n",
            "print_info: n_swa            = 0\n",
            "print_info: is_swa_any       = 0\n",
            "print_info: n_embd_head_k    = 128\n",
            "print_info: n_embd_head_v    = 128\n",
            "print_info: n_gqa            = 4\n",
            "print_info: n_embd_k_gqa     = 1024\n",
            "print_info: n_embd_v_gqa     = 1024\n",
            "print_info: f_norm_eps       = 0.0e+00\n",
            "print_info: f_norm_rms_eps   = 1.0e-05\n",
            "print_info: f_clamp_kqv      = 0.0e+00\n",
            "print_info: f_max_alibi_bias = 0.0e+00\n",
            "print_info: f_logit_scale    = 0.0e+00\n",
            "print_info: f_attn_scale     = 0.0e+00\n",
            "print_info: n_ff             = 14336\n",
            "print_info: n_expert         = 0\n",
            "print_info: n_expert_used    = 0\n",
            "print_info: causal attn      = 1\n",
            "print_info: pooling type     = 0\n",
            "print_info: rope type        = 0\n",
            "print_info: rope scaling     = linear\n",
            "print_info: freq_base_train  = 1000000.0\n",
            "print_info: freq_scale_train = 1\n",
            "print_info: n_ctx_orig_yarn  = 32768\n",
            "print_info: rope_finetuned   = unknown\n",
            "print_info: ssm_d_conv       = 0\n",
            "print_info: ssm_d_inner      = 0\n",
            "print_info: ssm_d_state      = 0\n",
            "print_info: ssm_dt_rank      = 0\n",
            "print_info: ssm_dt_b_c_rms   = 0\n",
            "print_info: model type       = 7B\n",
            "print_info: model params     = 7.24 B\n",
            "print_info: general.name     = mistralai_mistral-7b-instruct-v0.2\n",
            "print_info: vocab type       = SPM\n",
            "print_info: n_vocab          = 32000\n",
            "print_info: n_merges         = 0\n",
            "print_info: BOS token        = 1 '<s>'\n",
            "print_info: EOS token        = 2 '</s>'\n",
            "print_info: UNK token        = 0 '<unk>'\n",
            "print_info: PAD token        = 0 '<unk>'\n",
            "print_info: LF token         = 13 '<0x0A>'\n",
            "print_info: EOG token        = 2 '</s>'\n",
            "print_info: max token length = 48\n",
            "load_tensors: loading model tensors, this can take a while... (mmap = true)\n",
            "load_tensors: layer   0 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer   1 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer   2 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer   3 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer   4 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer   5 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer   6 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer   7 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer   8 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer   9 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer  10 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer  11 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer  12 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer  13 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer  14 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer  15 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer  16 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer  17 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer  18 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer  19 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer  20 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer  21 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer  22 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer  23 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer  24 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer  25 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer  26 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer  27 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer  28 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer  29 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer  30 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer  31 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer  32 assigned to device CPU, is_swa = 0\n",
            "load_tensors: tensor 'token_embd.weight' (q6_K) (and 290 others) cannot be used with preferred buffer type CPU_REPACK, using CPU instead\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model downloaded to: /root/.cache/huggingface/hub/models--TheBloke--Mistral-7B-Instruct-v0.2-GGUF/snapshots/3a6fbf4a41a1d52e415a4958cde6856d34b2db93/mistral-7b-instruct-v0.2.Q6_K.gguf\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "load_tensors:   CPU_Mapped model buffer size =  5666.09 MiB\n",
            "...................................................................................................\n",
            "llama_context: constructing llama_context\n",
            "llama_context: n_seq_max     = 1\n",
            "llama_context: n_ctx         = 2300\n",
            "llama_context: n_ctx_per_seq = 2300\n",
            "llama_context: n_batch       = 128\n",
            "llama_context: n_ubatch      = 128\n",
            "llama_context: causal_attn   = 1\n",
            "llama_context: flash_attn    = 0\n",
            "llama_context: freq_base     = 1000000.0\n",
            "llama_context: freq_scale    = 1\n",
            "llama_context: n_ctx_per_seq (2300) < n_ctx_train (32768) -- the full capacity of the model will not be utilized\n",
            "set_abort_callback: call\n",
            "llama_context:        CPU  output buffer size =     0.12 MiB\n",
            "create_memory: n_ctx = 2304 (padded)\n",
            "llama_kv_cache_unified: layer   0: dev = CPU\n",
            "llama_kv_cache_unified: layer   1: dev = CPU\n",
            "llama_kv_cache_unified: layer   2: dev = CPU\n",
            "llama_kv_cache_unified: layer   3: dev = CPU\n",
            "llama_kv_cache_unified: layer   4: dev = CPU\n",
            "llama_kv_cache_unified: layer   5: dev = CPU\n",
            "llama_kv_cache_unified: layer   6: dev = CPU\n",
            "llama_kv_cache_unified: layer   7: dev = CPU\n",
            "llama_kv_cache_unified: layer   8: dev = CPU\n",
            "llama_kv_cache_unified: layer   9: dev = CPU\n",
            "llama_kv_cache_unified: layer  10: dev = CPU\n",
            "llama_kv_cache_unified: layer  11: dev = CPU\n",
            "llama_kv_cache_unified: layer  12: dev = CPU\n",
            "llama_kv_cache_unified: layer  13: dev = CPU\n",
            "llama_kv_cache_unified: layer  14: dev = CPU\n",
            "llama_kv_cache_unified: layer  15: dev = CPU\n",
            "llama_kv_cache_unified: layer  16: dev = CPU\n",
            "llama_kv_cache_unified: layer  17: dev = CPU\n",
            "llama_kv_cache_unified: layer  18: dev = CPU\n",
            "llama_kv_cache_unified: layer  19: dev = CPU\n",
            "llama_kv_cache_unified: layer  20: dev = CPU\n",
            "llama_kv_cache_unified: layer  21: dev = CPU\n",
            "llama_kv_cache_unified: layer  22: dev = CPU\n",
            "llama_kv_cache_unified: layer  23: dev = CPU\n",
            "llama_kv_cache_unified: layer  24: dev = CPU\n",
            "llama_kv_cache_unified: layer  25: dev = CPU\n",
            "llama_kv_cache_unified: layer  26: dev = CPU\n",
            "llama_kv_cache_unified: layer  27: dev = CPU\n",
            "llama_kv_cache_unified: layer  28: dev = CPU\n",
            "llama_kv_cache_unified: layer  29: dev = CPU\n",
            "llama_kv_cache_unified: layer  30: dev = CPU\n",
            "llama_kv_cache_unified: layer  31: dev = CPU\n",
            "llama_kv_cache_unified:        CPU KV buffer size =   288.00 MiB\n",
            "llama_kv_cache_unified: size =  288.00 MiB (  2304 cells,  32 layers,  1 seqs), K (f16):  144.00 MiB, V (f16):  144.00 MiB\n",
            "llama_context: enumerating backends\n",
            "llama_context: backend_ptrs.size() = 1\n",
            "llama_context: max_nodes = 65536\n",
            "llama_context: worst-case: n_tokens = 128, n_seqs = 1, n_outputs = 0\n",
            "graph_reserve: reserving a graph for ubatch with n_tokens =  128, n_seqs =  1, n_outputs =  128\n",
            "graph_reserve: reserving a graph for ubatch with n_tokens =    1, n_seqs =  1, n_outputs =    1\n",
            "graph_reserve: reserving a graph for ubatch with n_tokens =  128, n_seqs =  1, n_outputs =  128\n",
            "llama_context:        CPU compute buffer size =    45.13 MiB\n",
            "llama_context: graph nodes  = 1158\n",
            "llama_context: graph splits = 1\n",
            "CPU : SSE3 = 1 | SSSE3 = 1 | AVX = 1 | AVX2 = 1 | F16C = 1 | FMA = 1 | BMI2 = 1 | AVX512 = 1 | AVX512_VNNI = 1 | LLAMAFILE = 1 | OPENMP = 1 | REPACK = 1 | \n",
            "Model metadata: {'tokenizer.chat_template': \"{{ bos_token }}{% for message in messages %}{% if (message['role'] == 'user') != (loop.index0 % 2 == 0) %}{{ raise_exception('Conversation roles must alternate user/assistant/user/assistant/...') }}{% endif %}{% if message['role'] == 'user' %}{{ '[INST] ' + message['content'] + ' [/INST]' }}{% elif message['role'] == 'assistant' %}{{ message['content'] + eos_token}}{% else %}{{ raise_exception('Only user and assistant roles are supported!') }}{% endif %}{% endfor %}\", 'tokenizer.ggml.add_eos_token': 'false', 'tokenizer.ggml.padding_token_id': '0', 'tokenizer.ggml.unknown_token_id': '0', 'tokenizer.ggml.eos_token_id': '2', 'general.architecture': 'llama', 'llama.rope.freq_base': '1000000.000000', 'llama.context_length': '32768', 'general.name': 'mistralai_mistral-7b-instruct-v0.2', 'tokenizer.ggml.add_bos_token': 'true', 'llama.embedding_length': '4096', 'llama.feed_forward_length': '14336', 'llama.attention.layer_norm_rms_epsilon': '0.000010', 'llama.rope.dimension_count': '128', 'tokenizer.ggml.bos_token_id': '1', 'llama.attention.head_count': '32', 'llama.block_count': '32', 'llama.attention.head_count_kv': '8', 'general.quantization_version': '2', 'tokenizer.ggml.model': 'llama', 'general.file_type': '18'}\n",
            "Available chat formats from metadata: chat_template.default\n",
            "Guessed chat format: mistral-instruct\n"
          ]
        }
      ],
      "source": [
        "model_name_or_path = \"TheBloke/Mistral-7B-Instruct-v0.2-GGUF\"\n",
        "model_basename = \"mistral-7b-instruct-v0.2.Q6_K.gguf\"\n",
        "\n",
        "\n",
        "model_path = hf_hub_download(\n",
        "    repo_id=model_name_or_path,\n",
        "    filename=model_basename\n",
        ")\n",
        "\n",
        "print(f\"Model downloaded to: {model_path}\")\n",
        "\n",
        "llm = Llama(\n",
        "    model_path=model_path,\n",
        "    n_ctx=2300,\n",
        "    n_gpu_layers=8,\n",
        "    n_batch=128\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EzzkvIXvFTS4"
      },
      "source": [
        "#### Response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hG_IaZj0QLw4"
      },
      "outputs": [],
      "source": [
        "# Temparature is kept at 0 because for this business use case we want factual answers\n",
        "\n",
        "def response(query,max_tokens=200,temperature=0,top_p=0.95,top_k=50):\n",
        "    model_output = llm(\n",
        "      prompt=query,\n",
        "      max_tokens=max_tokens,\n",
        "      temperature=temperature,\n",
        "      top_p=top_p,\n",
        "      top_k=top_k\n",
        "    )\n",
        "\n",
        "    return model_output['choices'][0]['text']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K8YgK91SFjVY"
      },
      "source": [
        "### Query 1: What is the protocol for managing sepsis in a critical care unit?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-JLIVmpPQH0f",
        "outputId": "c30e044d-5ffb-45fe-b1db-5597b577068a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "llama_perf_context_print:        load time =    1484.88 ms\n",
            "llama_perf_context_print: prompt eval time =    1484.31 ms /    16 tokens (   92.77 ms per token,    10.78 tokens per second)\n",
            "llama_perf_context_print:        eval time =   31809.02 ms /   199 runs   (  159.84 ms per token,     6.26 tokens per second)\n",
            "llama_perf_context_print:       total time =   33414.93 ms /   215 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Sepsis is a life-threatening condition that can arise from an infection, and it requires prompt recognition and aggressive management in a critical care unit. The following are the general steps for managing sepsis in a critical care unit:\n",
            "\n",
            "1. Early recognition and suspicion: Septic patients may present with non-specific symptoms such as fever, chills, tachycardia, tachypnea, altered mental status, or lactic acidosis. It is essential to have a high index of suspicion for sepsis, especially in patients with known infections or risk factors.\n",
            "2. Initial assessment and resuscitation: The first step in managing sepsis is to assess and resuscitate the patient. This includes assessing airway, breathing, circulation, and disability (ABCD) and providing appropriate interventions such as oxygen therapy, fluid resuscitation, and vasopressor support if necessary.\n",
            "3. Source control:\n"
          ]
        }
      ],
      "source": [
        "query1 = \"What is the protocol for managing sepsis in a critical care unit?\"\n",
        "print(response(query1))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J6yxICeVFjVc"
      },
      "source": [
        "### Query 2: What are the common symptoms for appendicitis, and can it be cured via medicine? If not, what surgical procedure should be followed to treat it?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BdiHRgEqQIP9",
        "outputId": "35688c37-067e-41c5-c774-efc726347127"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: 2 prefix-match hit, remaining 32 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    1484.88 ms\n",
            "llama_perf_context_print: prompt eval time =    3190.47 ms /    32 tokens (   99.70 ms per token,    10.03 tokens per second)\n",
            "llama_perf_context_print:        eval time =   32822.60 ms /   199 runs   (  164.94 ms per token,     6.06 tokens per second)\n",
            "llama_perf_context_print:       total time =   36132.31 ms /   231 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Appendicitis is a medical condition characterized by inflammation of the appendix, a small pouch that extends from the cecum, the first part of the large intestine. The symptoms of appendicitis can vary from person to person, but the following are the most common:\n",
            "\n",
            "1. Abdominal pain: The pain is typically located in the lower right side of the abdomen and may be dull at first, but it can quickly become sharp and severe. The pain may worsen when you move, cough, or sneeze.\n",
            "2. Loss of appetite: You may lose your appetite due to the abdominal pain or feel nauseous.\n",
            "3. Nausea and vomiting: You may feel sick to your stomach and vomit.\n",
            "4. Fever: A fever of 100.4°F (38°C) or higher is common with appendicitis.\n",
            "5. Const\n"
          ]
        }
      ],
      "source": [
        "query2 = \"What are the common symptoms for appendicitis, and can it be cured via medicine? If not, what surgical procedure should be followed to treat it?\"\n",
        "print(response(query2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oflaoOGiFjVd"
      },
      "source": [
        "### Query 3: What are the effective treatments or solutions for addressing sudden patchy hair loss, commonly seen as localized bald spots on the scalp, and what could be the possible causes behind it?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N-mx9yboQIt-",
        "outputId": "d832db6d-ad9f-4747-c97a-3275ed881329"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: 4 prefix-match hit, remaining 34 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    1484.88 ms\n",
            "llama_perf_context_print: prompt eval time =    2447.22 ms /    34 tokens (   71.98 ms per token,    13.89 tokens per second)\n",
            "llama_perf_context_print:        eval time =   32804.30 ms /   199 runs   (  164.85 ms per token,     6.07 tokens per second)\n",
            "llama_perf_context_print:       total time =   35372.69 ms /   233 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Sudden patchy hair loss, also known as alopecia areata, is a common autoimmune disorder that affects the hair follicles, leading to hair loss in small, round patches on the scalp, beard, or other areas of the body. The exact cause of alopecia areata is not known, but it is believed to be related to a problem with the immune system.\n",
            "\n",
            "There are several treatments that have been shown to be effective in addressing sudden patchy hair loss:\n",
            "\n",
            "1. Corticosteroids: Corticosteroids are anti-inflammatory medications that can help reduce inflammation and suppress the immune system, allowing the hair follicles to regrow. They can be applied topically or taken orally.\n",
            "2. Minoxidil: Minoxidil is a medication that has been shown to promote hair growth in some people with alopecia areata. It is applied\n"
          ]
        }
      ],
      "source": [
        "query3 = \"What are the effective treatments or solutions for addressing sudden patchy hair loss, commonly seen as localized bald spots on the scalp, and what could be the possible causes behind it?\"\n",
        "print(response(query3))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WUUqY4FbFjVe"
      },
      "source": [
        "### Query 4:  What treatments are recommended for a person who has sustained a physical injury to brain tissue, resulting in temporary or permanent impairment of brain function?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TEsVMaKaQJzh",
        "outputId": "369ecc47-84cd-4d07-a578-2f08c52137ac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: 2 prefix-match hit, remaining 28 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    1484.88 ms\n",
            "llama_perf_context_print: prompt eval time =    2003.62 ms /    28 tokens (   71.56 ms per token,    13.97 tokens per second)\n",
            "llama_perf_context_print:        eval time =   32784.29 ms /   199 runs   (  164.75 ms per token,     6.07 tokens per second)\n",
            "llama_perf_context_print:       total time =   34911.69 ms /   227 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "A person who has sustained a physical injury to brain tissue, resulting in temporary or permanent impairment of brain function, is typically diagnosed with a traumatic brain injury (TBI). The treatment for a TBI depends on the severity and location of the injury, as well as the individual's overall health and age.\n",
            "\n",
            "Immediate treatment for a TBI may include:\n",
            "\n",
            "1. Emergency medical care: This may include surgery to remove hematomas or other obstructions, as well as treatment for other injuries.\n",
            "2. Medications: Depending on the symptoms, medications may be prescribed to manage pain, reduce swelling, prevent or treat infections, or control seizures.\n",
            "3. Rehabilitation: Rehabilitation may include physical therapy, occupational therapy, speech therapy, and cognitive rehabilitation to help the person regain lost skills and functions.\n",
            "4. Supportive care: This may include assistance with daily activities\n"
          ]
        }
      ],
      "source": [
        "query4 = \"What treatments are recommended for a person who has sustained a physical injury to brain tissue, resulting in temporary or permanent impairment of brain function?\"\n",
        "print(response(query4))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5laPFTHrFjVf"
      },
      "source": [
        "### Query 5: What are the necessary precautions and treatment steps for a person who has fractured their leg during a hiking trip, and what should be considered for their care and recovery?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VfrlmrP5QKJz",
        "outputId": "1204dd74-0251-4a95-cba2-5eca5537e7db"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: 2 prefix-match hit, remaining 35 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    1484.88 ms\n",
            "llama_perf_context_print: prompt eval time =    2505.09 ms /    35 tokens (   71.57 ms per token,    13.97 tokens per second)\n",
            "llama_perf_context_print:        eval time =   32807.68 ms /   199 runs   (  164.86 ms per token,     6.07 tokens per second)\n",
            "llama_perf_context_print:       total time =   35434.18 ms /   234 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "First and foremost, if a person has fractured their leg during a hiking trip, it is essential to ensure their safety and prevent further injury. Here are some necessary precautions and treatment steps:\n",
            "\n",
            "1. Assess the situation: Check the extent of the injury and assess the person's condition. If the fracture is open or the person is in severe pain, immobilize the leg with a splint or a makeshift sling to prevent any movement.\n",
            "2. Call for help: If possible, call for emergency medical assistance. If there is no cell phone reception, try to signal for help using a mirror, whistle, or other means.\n",
            "3. Provide first aid: Apply a sterile dressing to the injury to prevent infection. If the fracture is open, apply pressure to stop any bleeding.\n",
            "4. Immobilize the leg: Use a splint, a makeshift sling, or a tour\n"
          ]
        }
      ],
      "source": [
        "query5 = \"What are the necessary precautions and treatment steps for a person who has fractured their leg during a hiking trip, and what should be considered for their care and recovery?\"\n",
        "print(response(query5))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Response Quality: The LLM provides generally relevant and factually correct answers to medical queries, but the depth and specificity can vary. Some answers are incomplete or stop mid-sentence, especially for complex or multi-part questions.\n",
        "\n",
        "Consistency: There is occasional inconsistency in the level of detail. For example, some answers list only a few symptoms or steps, while others are more comprehensive.\n",
        "\n",
        "Limitations:\n",
        "\n",
        "The LLM sometimes omits critical context or nuances, such as when to escalate care or specific contraindications.\n",
        "\n",
        "Answers may lack explicit references to authoritative sources, which is important in medical settings.\n",
        "\n",
        "There is a risk of hallucination or overgeneralization, especially for less common or ambiguous queries."
      ],
      "metadata": {
        "id": "LSyGHjfjLjjR"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g5myZ5dOOefc"
      },
      "source": [
        "## Question Answering using LLM with Prompt Engineering"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V6zMUxFl1CuR",
        "outputId": "1a44eb0d-36cd-41b4-c418-ca6840642bb8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "System Prompt:You are a helpful and knowledgeable medical assistant. Answer the following medical question accurately and concisely based on common medical knowledge. If you don't know the answer, please state that you don't have enough information.\n"
          ]
        }
      ],
      "source": [
        "# Add instructions to the prompt for better response generation\n",
        "# Given the sensitivity of medical diagnosis, I am adding a prompt to minimize hallucination\n",
        "system_prompt = \"You are a helpful and knowledgeable medical assistant. Answer the following medical question accurately and concisely based on common medical knowledge. If you don't know the answer, please state that you don't have enough information.\"\n",
        "print (\"System Prompt:\" + system_prompt)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Jg3r_LWOeff"
      },
      "source": [
        "### Query 1: What is the protocol for managing sepsis in a critical care unit?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YqM4VMw5ROhX",
        "outputId": "9e506d7b-a861-4b26-ea12-cc26563b4bf8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: 1 prefix-match hit, remaining 61 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    1484.88 ms\n",
            "llama_perf_context_print: prompt eval time =    4299.52 ms /    61 tokens (   70.48 ms per token,    14.19 tokens per second)\n",
            "llama_perf_context_print:        eval time =   32964.31 ms /   199 runs   (  165.65 ms per token,     6.04 tokens per second)\n",
            "llama_perf_context_print:       total time =   37388.56 ms /   260 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Sepsis is a life-threatening condition caused by a severe infection. In a critical care unit, managing sepsis involves the following steps:\n",
            "\n",
            "1. Early recognition and diagnosis: Monitor vital signs, laboratory values, and clinical symptoms closely. Suspect sepsis in any patient with suspected or confirmed infection and organ dysfunction.\n",
            "2. Immediate fluid resuscitation: Administer intravenous fluids to maintain adequate blood pressure and organ perfusion. The goal is to achieve a mean arterial pressure (MAP) of 65 mmHg or higher.\n",
            "3. Antibiotics: Administer broad-spectrum antibiotics as soon as possible based on the suspected infection site and microbiological culture results.\n",
            "4. Source control: Identify and address the source of infection, such as removing an infected catheter or draining an abscess.\n",
            "5. Vasopressors: If fluid res\n"
          ]
        }
      ],
      "source": [
        "query1 = system_prompt + \"\\n\" + \"What is the protocol for managing sepsis in a critical care unit?\"\n",
        "print(response(query1))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iYpyw4HjOeff"
      },
      "source": [
        "### Query 2: What are the common symptoms for appendicitis, and can it be cured via medicine? If not, what surgical procedure should be followed to treat it?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GXl09pFfRPBr",
        "outputId": "1a14f2d2-8062-4abb-bf53-d79d631b2ac5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: 48 prefix-match hit, remaining 32 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    1484.88 ms\n",
            "llama_perf_context_print: prompt eval time =    2346.33 ms /    32 tokens (   73.32 ms per token,    13.64 tokens per second)\n",
            "llama_perf_context_print:        eval time =   32927.11 ms /   199 runs   (  165.46 ms per token,     6.04 tokens per second)\n",
            "llama_perf_context_print:       total time =   35394.40 ms /   231 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Appendicitis is a common inflammatory condition of the appendix, a small pouch located in the lower right side of the abdomen. The symptoms of appendicitis can include:\n",
            "\n",
            "1. Sudden pain in the lower right abdomen, which may start as a mild ache and gradually develop into a sharp pain.\n",
            "2. Loss of appetite and feeling sick to your stomach (nausea).\n",
            "3. Fever, which may be low-grade at first but can rise as high as 103°F (39.4°C).\n",
            "4. Vomiting.\n",
            "5. Constipation or diarrhea.\n",
            "6. Abdominal swelling and tenderness.\n",
            "7. Inability to pass gas or have a bowel movement.\n",
            "8. Pain in the lower back, on the right side.\n",
            "9. Feeling restless or unable to find a comfortable position.\n"
          ]
        }
      ],
      "source": [
        "query2 = system_prompt + \"\\n\" + \"What are the common symptoms for appendicitis, and can it be cured via medicine? If not, what surgical procedure should be followed to treat it?\"\n",
        "print(response(query2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dRp92JQZOeff"
      },
      "source": [
        "### Query 3: What are the effective treatments or solutions for addressing sudden patchy hair loss, commonly seen as localized bald spots on the scalp, and what could be the possible causes behind it?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JOgATEpMRPve",
        "outputId": "c16ab39a-c594-4673-c206-bf734b8a943e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: 50 prefix-match hit, remaining 34 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    1484.88 ms\n",
            "llama_perf_context_print: prompt eval time =    2478.53 ms /    34 tokens (   72.90 ms per token,    13.72 tokens per second)\n",
            "llama_perf_context_print:        eval time =   32968.36 ms /   199 runs   (  165.67 ms per token,     6.04 tokens per second)\n",
            "llama_perf_context_print:       total time =   35569.89 ms /   233 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Sudden patchy hair loss, also known as alopecia areata, is an autoimmune condition that causes hair loss in small, round patches on the scalp, beard, or other areas of the body. The exact cause is unknown, but it's believed to be related to a problem with the immune system.\n",
            "\n",
            "Effective treatments for addressing sudden patchy hair loss include:\n",
            "\n",
            "1. Corticosteroids: These are anti-inflammatory medications that can help reduce inflammation and suppress the immune system response. They can be applied topically or taken orally.\n",
            "2. Immunotherapy: This involves the use of medications that stimulate the immune system to attack the hair loss. One such medication is minoxidil.\n",
            "3. Hair transplantation: This is a surgical procedure in which healthy hair is transplanted from one area of the scalp to another. It's usually considered a\n"
          ]
        }
      ],
      "source": [
        "query3 = system_prompt + \"\\n\" + \"What are the effective treatments or solutions for addressing sudden patchy hair loss, commonly seen as localized bald spots on the scalp, and what could be the possible causes behind it?\"\n",
        "print(response(query3))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AA45zwyUOefg"
      },
      "source": [
        "### Query 4:  What treatments are recommended for a person who has sustained a physical injury to brain tissue, resulting in temporary or permanent impairment of brain function?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VA7G8FOnRQZY",
        "outputId": "c7513839-75dc-48b4-a7dd-a76363872eb8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: 48 prefix-match hit, remaining 28 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    1484.88 ms\n",
            "llama_perf_context_print: prompt eval time =    2329.08 ms /    28 tokens (   83.18 ms per token,    12.02 tokens per second)\n",
            "llama_perf_context_print:        eval time =   32839.01 ms /   199 runs   (  165.02 ms per token,     6.06 tokens per second)\n",
            "llama_perf_context_print:       total time =   35290.27 ms /   227 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "For a person who has sustained a physical injury to brain tissue, resulting in temporary or permanent impairment of brain function, the recommended treatments depend on the specific type and severity of the injury. Here are some common treatments:\n",
            "\n",
            "1. Emergency care: For severe brain injuries, the first priority is to provide emergency care to stabilize the patient's vital signs and prevent further damage. This may include surgery to remove hematomas or other obstructions, administering oxygen, and controlling seizures.\n",
            "2. Medications: Depending on the symptoms, medications may be prescribed to manage various conditions such as pain, seizures, infections, and depression.\n",
            "3. Rehabilitation: Rehabilitation is an essential part of treatment for brain injuries. It may include physical therapy to help the patient regain mobility, occupational therapy to help with daily living activities, speech therapy to improve communication skills, and cognitive therapy to help with memory and problem-\n"
          ]
        }
      ],
      "source": [
        "query4 = system_prompt + \"\\n\" + \"What treatments are recommended for a person who has sustained a physical injury to brain tissue, resulting in temporary or permanent impairment of brain function?\"\n",
        "print(response(query4))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TYXxiSuBOefg"
      },
      "source": [
        "### Query 5: What are the necessary precautions and treatment steps for a person who has fractured their leg during a hiking trip, and what should be considered for their care and recovery?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mE2GMQk8RQ_p",
        "outputId": "0bca7dfc-4c72-434d-c1ac-49ac15a915b5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: 48 prefix-match hit, remaining 35 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    1484.88 ms\n",
            "llama_perf_context_print: prompt eval time =    3638.63 ms /    35 tokens (  103.96 ms per token,     9.62 tokens per second)\n",
            "llama_perf_context_print:        eval time =   32906.03 ms /   199 runs   (  165.36 ms per token,     6.05 tokens per second)\n",
            "llama_perf_context_print:       total time =   36666.21 ms /   234 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "A leg fracture during a hiking trip requires prompt medical attention. Here are the necessary precautions and treatment steps:\n",
            "\n",
            "1. Immobilize the fracture: Use a splint, sling, or a brace to prevent any movement of the affected leg. This will help reduce pain, prevent further damage, and promote proper healing.\n",
            "\n",
            "2. Control bleeding: Apply direct pressure to the wound with a clean cloth to control any bleeding. Elevate the injured leg above heart level to help reduce swelling and bleeding.\n",
            "\n",
            "3. Seek medical help: If the fracture is severe or if there are signs of shock (pale skin, rapid heartbeat, rapid breathing, or loss of consciousness), call for emergency medical assistance immediately.\n",
            "\n",
            "4. Pain management: Use over-the-counter pain relievers, such as acetaminophen or ibuprofen, to help manage pain. Your healthcare provider may also prescribe\n"
          ]
        }
      ],
      "source": [
        "query5 = system_prompt + \"\\n\" + \"What are the necessary precautions and treatment steps for a person who has fractured their leg during a hiking trip, and what should be considered for their care and recovery?\"\n",
        "print(response(query5))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Response Quality: Prompt engineering (adding a system prompt to instruct the LLM to be concise, factual, and to admit uncertainty) improves the reliability and clarity of answers.\n",
        "\n",
        "Groundedness: The responses are more focused, with less speculation and fewer unsupported claims. The LLM is more likely to state when it lacks sufficient information.\n",
        "\n",
        "Structure: Answers are better organized, often using lists or stepwise instructions, which enhances readability for clinical users.\n",
        "\n",
        "Limitations:\n",
        "\n",
        "While hallucinations are reduced, the LLM still relies on its training data and may not always reflect the most current or authoritative medical guidelines.\n",
        "\n",
        "The model does not cite specific sources, which can be a drawback for clinical auditability."
      ],
      "metadata": {
        "id": "k_-fmq-rLnaa"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t_O1PGdNO2M9"
      },
      "source": [
        "## Data Preparation for RAG"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uTpWESc53dL9"
      },
      "source": [
        "### Loading the Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ybj2cEnzRSXq"
      },
      "outputs": [],
      "source": [
        "## Data Preparation for RAG\n",
        "### Loading the Data\n",
        "#Libraries for processing dataframes, text\n",
        "import json, os\n",
        "import tiktoken\n",
        "import pandas as pd\n",
        "\n",
        "#Libraries for Loading Data, Chunking, Embedding, and Vector Databases\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain_community.document_loaders import PyMuPDFLoader\n",
        "from langchain_community.embeddings.sentence_transformer import SentenceTransformerEmbeddings\n",
        "from langchain_community.vectorstores import Chroma"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ffj0ca3eZT4u"
      },
      "source": [
        "### Data Overview"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PEw2UChp-i8f",
        "outputId": "163ce220-b6cd-4ec0-b999-a144c48abcff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded 4114 pages from the PDF.\n"
          ]
        }
      ],
      "source": [
        "## Data Overview\n",
        "\n",
        "\n",
        "pdf_path = \"/content/medical_diagnosis_manual.pdf\"\n",
        "if not os.path.exists(pdf_path):\n",
        "    raise FileNotFoundError(f\"PDF not found at {pdf_path}\")\n",
        "\n",
        "# Use the PyMuPDFLoader to load the document\n",
        "try:\n",
        "    # Note: Loading large PDFs (>4,000 pages) may require significant memory. Consider chunked processing if RAM is limited.\n",
        "    loader = PyMuPDFLoader(pdf_path)\n",
        "    documents = loader.load()\n",
        "    print(f\"Loaded {len(documents)} pages from the PDF.\")\n",
        "except Exception as e:\n",
        "    print(f\"Error loading PDF: {e}\")\n",
        "    raise"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f9weTDzMxRRS"
      },
      "source": [
        "#### Checking the first 5 pages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MSEiL--bRTZT",
        "outputId": "318c8de0-baa2-4819-9771-0a1ea6fe9e5b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Page 1 ---\n",
            "anuguthalasandeepkumar@gmail.com\n",
            "KUDXERABSF\n",
            "personal use by anuguthalasandeepkum\n",
            "shing the contents in part or full is liable...\n",
            "--- Page 2 ---\n",
            "anuguthalasandeepkumar@gmail.com\n",
            "KUDXERABSF\n",
            "This file is meant for personal use by anuguthalasandeepkumar@gmail.com only.\n",
            "Sharing or publishing the contents in part or full is liable for legal action....\n",
            "--- Page 3 ---\n",
            "Table of Contents\n",
            "1\n",
            "Front    ................................................................................................................................................................................................................\n",
            "1\n",
            "Cover    .......................................................................................................................................................................................................\n",
            "2\n",
            "Front Matter    ....................................\n",
            "--- Page 4 ---\n",
            "491\n",
            "Chapter 44. Foot & Ankle Disorders    .....................................................................................................................................\n",
            "502\n",
            "Chapter 45. Tumors of Bones & Joints    ...............................................................................................................................\n",
            "510\n",
            "5 - Ear, Nose, Throat & Dental Disorders    ...........................................................................................................\n",
            "--- Page 5 ---\n",
            "921\n",
            "Chapter 94. Adrenal Disorders    ................................................................................................................................................\n",
            "936\n",
            "Chapter 95. Polyglandular Deficiency Syndromes    ........................................................................................................\n",
            "939\n",
            "Chapter 96. Porphyrias    ....................................................................................................................................\n",
            "Number of pages: 4114\n"
          ]
        }
      ],
      "source": [
        "# Preview first 5 pages (or fewer if PDF is smaller) for debugging\n",
        "for i in range(min(5, len(documents))):\n",
        "    print(f\"--- Page {i+1} ---\")\n",
        "    print(documents[i].page_content[:500] + \"...\")\n",
        "\n",
        "#### Checking the number of pages\n",
        "print(f\"Number of pages: {len(documents)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7-wNNalNxPKT"
      },
      "source": [
        "#### Checking the number of pages"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LECMxTH-zB-R"
      },
      "source": [
        "### Data Chunking"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ir9Zi8rKRUmG"
      },
      "outputs": [],
      "source": [
        "## Function to do data chunking\n",
        "\n",
        "def get_data_chunks(\n",
        "    data,\n",
        "    chunk_size=1000,\n",
        "    chunk_overlap=200,\n",
        "    split_method=\"recursive\",\n",
        "    separators=[\"\\n\\n\", \"\\n\", \". \", \" \", \"\"],\n",
        "    min_chunk_size=50,\n",
        "    respect_sentence_boundaries=True,\n",
        "    respect_paragraph_boundaries=True,\n",
        "    length_function=len,\n",
        "    max_chunks=None,\n",
        "    add_metadata=True\n",
        "):\n",
        "    \"\"\"\n",
        "    Splits a list of documents into smaller chunks using a specified method.\n",
        "\n",
        "    Args:\n",
        "        data: A list of document objects (e.g., from Langchain loaders).\n",
        "        chunk_size: The maximum size of each chunk.\n",
        "        chunk_overlap: The number of characters to overlap between chunks.\n",
        "        split_method: The method to use for splitting ('recursive').\n",
        "        separators: A list of separators to use for splitting.\n",
        "        min_chunk_size: The minimum size of each chunk.\n",
        "        respect_sentence_boundaries: Whether to try to split on sentence boundaries.\n",
        "        respect_paragraph_boundaries: Whether to try to split on paragraph boundaries.\n",
        "        length_function: The function to use to measure chunk length.\n",
        "        max_chunks: The maximum number of chunks to generate.\n",
        "        add_metadata: Whether to add metadata to the chunks.\n",
        "\n",
        "    Returns:\n",
        "        A list of chunked documents.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        if split_method == \"recursive\":\n",
        "            text_splitter = RecursiveCharacterTextSplitter(\n",
        "                chunk_size=chunk_size,\n",
        "                chunk_overlap=chunk_overlap,\n",
        "                length_function=length_function,\n",
        "                is_separator_regex=False,\n",
        "                separators=separators\n",
        "            )\n",
        "            chunks = text_splitter.split_documents(data)\n",
        "        else:\n",
        "            raise ValueError(f\"Unsupported split_method: {split_method}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error during chunking: {e}\")\n",
        "        raise\n",
        "    chunks = [chunk for chunk in chunks if length_function(chunk.page_content) >= min_chunk_size]\n",
        "    if add_metadata:\n",
        "        for chunk in chunks:\n",
        "            if not chunk.metadata:\n",
        "                chunk.metadata = {\"source\": \"medical_diagnosis_manual.pdf\", \"page\": 0}  # Fallback\n",
        "    if max_chunks is not None:\n",
        "        chunks = chunks[:max_chunks]\n",
        "    return chunks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g9_lKsfRCGhv",
        "outputId": "96d9b43d-02e5-470e-c52d-2852391dc348"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Chunking Validation ---\n",
            "Number of documents loaded: 4114\n",
            "Number of chunks created: 34743\n",
            "\n",
            "First 5 chunks:\n",
            "--- Chunk 1 ---\n",
            "Chunk length: 125\n",
            "Chunk metadata: {'producer': 'pdf-lib (https://github.com/Hopding/pdf-lib)', 'creator': 'Atop CHM to PDF Converter', 'creationdate': '2012-06-15T05:44:40+00:00', 'source': '/content/medical_diagnosis_manual.pdf', 'file_path': '/content/medical_diagnosis_manual.pdf', 'total_pages': 4114, 'format': 'PDF 1.7', 'title': 'The Merck Manual of Diagnosis & Therapy, 19th Edition', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-06-29T17:52:08+00:00', 'trapped': '', 'modDate': 'D:20250629175208Z', 'creationDate': 'D:20120615054440Z', 'page': 0}\n",
            "anuguthalasandeepkumar@gmail.com\n",
            "KUDXERABSF\n",
            "personal use by anuguthalasandeepkum\n",
            "shing the contents in part or full is liable...\n",
            "--- Chunk 2 ---\n",
            "Chunk length: 200\n",
            "Chunk metadata: {'producer': 'pdf-lib (https://github.com/Hopding/pdf-lib)', 'creator': 'Atop CHM to PDF Converter', 'creationdate': '2012-06-15T05:44:40+00:00', 'source': '/content/medical_diagnosis_manual.pdf', 'file_path': '/content/medical_diagnosis_manual.pdf', 'total_pages': 4114, 'format': 'PDF 1.7', 'title': 'The Merck Manual of Diagnosis & Therapy, 19th Edition', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-06-29T17:52:08+00:00', 'trapped': '', 'modDate': 'D:20250629175208Z', 'creationDate': 'D:20120615054440Z', 'page': 1}\n",
            "anuguthalasandeepkumar@gmail.com\n",
            "KUDXERABSF\n",
            "This file is meant for personal use by anuguthalasandeepkumar@gmail.com only.\n",
            "Sharing or publishing the contents in part or full is liable for legal action....\n",
            "--- Chunk 3 ---\n",
            "Chunk length: 450\n",
            "Chunk metadata: {'producer': 'pdf-lib (https://github.com/Hopding/pdf-lib)', 'creator': 'Atop CHM to PDF Converter', 'creationdate': '2012-06-15T05:44:40+00:00', 'source': '/content/medical_diagnosis_manual.pdf', 'file_path': '/content/medical_diagnosis_manual.pdf', 'total_pages': 4114, 'format': 'PDF 1.7', 'title': 'The Merck Manual of Diagnosis & Therapy, 19th Edition', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-06-29T17:52:08+00:00', 'trapped': '', 'modDate': 'D:20250629175208Z', 'creationDate': 'D:20120615054440Z', 'page': 2}\n",
            "Table of Contents\n",
            "1\n",
            "Front    ..............................................................................................................................................................................\n",
            "--- Chunk 4 ---\n",
            "Chunk length: 400\n",
            "Chunk metadata: {'producer': 'pdf-lib (https://github.com/Hopding/pdf-lib)', 'creator': 'Atop CHM to PDF Converter', 'creationdate': '2012-06-15T05:44:40+00:00', 'source': '/content/medical_diagnosis_manual.pdf', 'file_path': '/content/medical_diagnosis_manual.pdf', 'total_pages': 4114, 'format': 'PDF 1.7', 'title': 'The Merck Manual of Diagnosis & Therapy, 19th Edition', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-06-29T17:52:08+00:00', 'trapped': '', 'modDate': 'D:20250629175208Z', 'creationDate': 'D:20120615054440Z', 'page': 2}\n",
            "2\n",
            "Front Matter    .........................................................................................................................................................................................\n",
            "--- Chunk 5 ---\n",
            "Chunk length: 361\n",
            "Chunk metadata: {'producer': 'pdf-lib (https://github.com/Hopding/pdf-lib)', 'creator': 'Atop CHM to PDF Converter', 'creationdate': '2012-06-15T05:44:40+00:00', 'source': '/content/medical_diagnosis_manual.pdf', 'file_path': '/content/medical_diagnosis_manual.pdf', 'total_pages': 4114, 'format': 'PDF 1.7', 'title': 'The Merck Manual of Diagnosis & Therapy, 19th Edition', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-06-29T17:52:08+00:00', 'trapped': '', 'modDate': 'D:20250629175208Z', 'creationDate': 'D:20120615054440Z', 'page': 2}\n",
            "53\n",
            "Chapter 1. Nutrition: General Considerations    .....................................................................................................................\n",
            "59\n",
            "Chapter 2. Undernutrition   ...\n",
            "\n",
            "Last 5 chunks:\n",
            "--- Chunk 34739 ---\n",
            "Chunk length: 358\n",
            "Chunk metadata: {'producer': 'pdf-lib (https://github.com/Hopding/pdf-lib)', 'creator': 'Atop CHM to PDF Converter', 'creationdate': '2012-06-15T05:44:40+00:00', 'source': '/content/medical_diagnosis_manual.pdf', 'file_path': '/content/medical_diagnosis_manual.pdf', 'total_pages': 4114, 'format': 'PDF 1.7', 'title': 'The Merck Manual of Diagnosis & Therapy, 19th Edition', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-06-29T17:52:08+00:00', 'trapped': '', 'modDate': 'D:20250629175208Z', 'creationDate': 'D:20120615054440Z', 'page': 4112}\n",
            "Y. pestis infection 1924\n",
            "Yew poisoning 3338\n",
            "Yips 1762\n",
            "Yo, antibodies to 1056\n",
            "Yolk sac tumor 2476\n",
            "The Merck Manual of Diagnosis & Therapy, 19th Edition\n",
            "Y\n",
            "4103\n",
            "anuguthalasandeepkumar@gmail.com\n",
            "KUDXERABS...\n",
            "--- Chunk 34740 ---\n",
            "Chunk length: 492\n",
            "Chunk metadata: {'producer': 'pdf-lib (https://github.com/Hopding/pdf-lib)', 'creator': 'Atop CHM to PDF Converter', 'creationdate': '2012-06-15T05:44:40+00:00', 'source': '/content/medical_diagnosis_manual.pdf', 'file_path': '/content/medical_diagnosis_manual.pdf', 'total_pages': 4114, 'format': 'PDF 1.7', 'title': 'The Merck Manual of Diagnosis & Therapy, 19th Edition', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-06-29T17:52:08+00:00', 'trapped': '', 'modDate': 'D:20250629175208Z', 'creationDate': 'D:20120615054440Z', 'page': 4113}\n",
            "Z\n",
            "Zafirlukast 1879\n",
            "Zalcitabine 1451\n",
            "in children 2854\n",
            "Zaleplon 1709\n",
            "Zanamivir 1407\n",
            "in influenza 1407, 1929\n",
            "ZAP-70 (zeta-associated protein 70) deficiency 1092, 1108\n",
            "Zavanelli maneuver 2680\n",
            "Zellweger sy...\n",
            "--- Chunk 34741 ---\n",
            "Chunk length: 484\n",
            "Chunk metadata: {'producer': 'pdf-lib (https://github.com/Hopding/pdf-lib)', 'creator': 'Atop CHM to PDF Converter', 'creationdate': '2012-06-15T05:44:40+00:00', 'source': '/content/medical_diagnosis_manual.pdf', 'file_path': '/content/medical_diagnosis_manual.pdf', 'total_pages': 4114, 'format': 'PDF 1.7', 'title': 'The Merck Manual of Diagnosis & Therapy, 19th Edition', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-06-29T17:52:08+00:00', 'trapped': '', 'modDate': 'D:20250629175208Z', 'creationDate': 'D:20120615054440Z', 'page': 4113}\n",
            "poisoning with 3328, 3353\n",
            "recommended dietary allowances for 50\n",
            "reference values for 3499\n",
            "toxicity of 49, 55\n",
            "copper deficiency and 49\n",
            "in Wilson's disease 52\n",
            "Zinc oxide 2233\n",
            "gelatin formulation of 646,...\n",
            "--- Chunk 34742 ---\n",
            "Chunk length: 469\n",
            "Chunk metadata: {'producer': 'pdf-lib (https://github.com/Hopding/pdf-lib)', 'creator': 'Atop CHM to PDF Converter', 'creationdate': '2012-06-15T05:44:40+00:00', 'source': '/content/medical_diagnosis_manual.pdf', 'file_path': '/content/medical_diagnosis_manual.pdf', 'total_pages': 4114, 'format': 'PDF 1.7', 'title': 'The Merck Manual of Diagnosis & Therapy, 19th Edition', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-06-29T17:52:08+00:00', 'trapped': '', 'modDate': 'D:20250629175208Z', 'creationDate': 'D:20120615054440Z', 'page': 4113}\n",
            "Zollinger-Ellison syndrome 95, 199, 200-201, 910\n",
            "mastocytosis vs 1125\n",
            "Menetrier's disease vs 132\n",
            "peptic ulcer disease vs 134\n",
            "Zolmitriptan 1721\n",
            "Zolpidem 1709, 3103\n",
            "Zonisamide 1701\n",
            "Zoonotic diseases, cu...\n",
            "--- Chunk 34743 ---\n",
            "Chunk length: 167\n",
            "Chunk metadata: {'producer': 'pdf-lib (https://github.com/Hopding/pdf-lib)', 'creator': 'Atop CHM to PDF Converter', 'creationdate': '2012-06-15T05:44:40+00:00', 'source': '/content/medical_diagnosis_manual.pdf', 'file_path': '/content/medical_diagnosis_manual.pdf', 'total_pages': 4114, 'format': 'PDF 1.7', 'title': 'The Merck Manual of Diagnosis & Therapy, 19th Edition', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-06-29T17:52:08+00:00', 'trapped': '', 'modDate': 'D:20250629175208Z', 'creationDate': 'D:20120615054440Z', 'page': 4113}\n",
            "KUDXERABSF\n",
            "This file is meant for personal use by anuguthalasandeepkumar@gmail.com only.\n",
            "Sharing or publishing the contents in part or full is liable for legal action....\n",
            "\n",
            "Minimum chunk length: 125\n",
            "Number of empty chunks: 0\n",
            "Number of chunks missing metadata: 0\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Utilize the get_data_chunks function for the loaded PDF\n",
        "chunk_size = 500  # chunk size\n",
        "chunk_overlap = 100 # chunk overlap\n",
        "\n",
        "chunks = get_data_chunks(\n",
        "    documents,\n",
        "    chunk_size=chunk_size,\n",
        "    chunk_overlap=chunk_overlap,\n",
        "    split_method=\"recursive\",\n",
        "    separators=[\"\\n\\n\", \"\\n\", \". \", \" \", \"\"],\n",
        "    min_chunk_size=50,\n",
        "    respect_sentence_boundaries=True,\n",
        "    respect_paragraph_boundaries=True,\n",
        "    length_function=len,\n",
        "    max_chunks=None, # Process all chunks\n",
        "    add_metadata=True\n",
        ")\n",
        "\n",
        "# Print some validation and check statements\n",
        "print(f\"\\n--- Chunking Validation ---\")\n",
        "print(f\"Number of documents loaded: {len(documents)}\")\n",
        "print(f\"Number of chunks created: {len(chunks)}\")\n",
        "\n",
        "# Check the first few chunks\n",
        "print(f\"\\nFirst {min(5, len(chunks))} chunks:\")\n",
        "for i in range(min(5, len(chunks))):\n",
        "  print(f\"--- Chunk {i+1} ---\")\n",
        "  print(f\"Chunk length: {len(chunks[i].page_content)}\")\n",
        "  print(f\"Chunk metadata: {chunks[i].metadata}\")\n",
        "  print(chunks[i].page_content[:200] + \"...\") # Print first 200 characters of the chunk content\n",
        "\n",
        "# Check the last few chunks (if there are more than 5)\n",
        "if len(chunks) > 5:\n",
        "    print(f\"\\nLast {min(5, len(chunks)-5)} chunks:\")\n",
        "    for i in range(max(0, len(chunks)-5), len(chunks)):\n",
        "        print(f\"--- Chunk {i+1} ---\")\n",
        "        print(f\"Chunk length: {len(chunks[i].page_content)}\")\n",
        "        print(f\"Chunk metadata: {chunks[i].metadata}\")\n",
        "        print(chunks[i].page_content[:200] + \"...\") # Print first 200 characters of the chunk content\n",
        "\n",
        "# Additional checks\n",
        "if len(chunks) > 0:\n",
        "    # Check minimum chunk size\n",
        "    min_len = min(len(chunk.page_content) for chunk in chunks)\n",
        "    print(f\"\\nMinimum chunk length: {min_len}\")\n",
        "    if min_len < 50: # Based on min_chunk_size parameter\n",
        "        print(\"Warning: Some chunks might be smaller than the specified minimum size.\")\n",
        "\n",
        "    # Check for empty chunks\n",
        "    empty_chunks = sum(1 for chunk in chunks if len(chunk.page_content) == 0)\n",
        "    print(f\"Number of empty chunks: {empty_chunks}\")\n",
        "\n",
        "    # Check metadata presence (assuming add_metadata is True)\n",
        "    metadata_missing = sum(1 for chunk in chunks if not hasattr(chunk, 'metadata') or not chunk.metadata)\n",
        "    print(f\"Number of chunks missing metadata: {metadata_missing}\")\n",
        "else:\n",
        "    print(\"\\nNo chunks were created.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BvHVejcWz0Bl"
      },
      "source": [
        "### Embedding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 580,
          "referenced_widgets": [
            "942653e57d0147c1820313e10c2d4195",
            "72ef9cb5e9af48148a1f6d89c3d4349d",
            "43122ff0685d4feaae391dfff7d7c3f4",
            "2c509a9e97f34a679a494270601b59dc",
            "431df39a2cfb4ce3a9c40cf839b36ef9",
            "33a227dbb5794b6180fe6d7fc49bf46f",
            "d753cb6b566a492e9cfe766ce1cb6214",
            "902c6298bc9547bbbea4e15a0faaf007",
            "3ce5fa657d3e4116a3b0afcd61ad5977",
            "a9e7b8f4dfe542fb91fd7cadf996c458",
            "7353ed65ab31404f938b81ab59913349",
            "82910528cb7640b986101f77dd2f0ef9",
            "70aa7a3a618e43109bfefe13d22780d6",
            "a045bb70be7a4d669081dafb8559897b",
            "d9485c21963d4a7fa04aad4707e65c6a",
            "b9a6ff8d65ef434bac89045afd60911b",
            "1872a02d29a54656a14205959ee6cfb9",
            "7695c4739a1144809ad0c82ea12bfad3",
            "f3b44230fcdb4fc996bd316cc4bdd8a3",
            "4ca3f5689b1a473f95041452dd3e8fe4",
            "d8c57ffc6ba5463aabd16046fcbe41a7",
            "25d60a2e2ec24ab1b3737551420ac608",
            "617c17d270a2472381227c064ddba078",
            "796dd9b5fcb14540aa5a9ad6cc4e147d",
            "efc5fee05c9f4675992a63d3bed2bc25",
            "29bc3990be3d4ac1a027c506d971f59b",
            "5c76edff32ee4700827025811fcc6b02",
            "91639ac6ff6a4dd88e022728ff478051",
            "f6980182dbf34758ae1178e0a08da54d",
            "c7feca5eae414769aeb7fafd1a66c8e6",
            "37164e6d95fd4b5c97c2f481e7d8e8bc",
            "05540166682b4db69a9651dc59c8b142",
            "86880a5e7b684378b6079a87a39b1020",
            "c5c287fef9c146cbb1da4111eeaae297",
            "c9e62369ecb648698514c16d9cbb31c2",
            "5439c8a8570243c593437b3d295e18b1",
            "01d945247bd04649a806c607368f2b1f",
            "0573c3b2bbac4209be0479334f4af0d7",
            "28af72495e1a4edc8a7cbd25868545ca",
            "43af3459b94049ceae59566b7fdbb0ea",
            "43ec165e754b4e09891046320418fe12",
            "904cf7a78cfd43cd947fd240d8eae614",
            "856bc1f1216044f29cff035a81c6c410",
            "90747b76bbd741a18c4a6f1264251934",
            "8afb980d3c3946dbb21f5c6cb23c9fef",
            "dea9d2927507438096b358cd5f5efe9f",
            "71efc6fc80524a0abe9d824715545b25",
            "73e5695db20f4506b164502bc4a032ea",
            "c7ca35b0377441c08b1656af34a4deef",
            "58ac866026474cf492fb6febbfec92d2",
            "131d431d602d4ffb99012fd94d0944c5",
            "f4cb1cb2f30942debc46edb6b4c055e3",
            "7c110b603c7c44669d713f6b8c3b8bbd",
            "c864923aa7584ef28cf802fa565c7dce",
            "4cab48bd01684a8cac63b5fcac5cc21b",
            "d4720bacfa7b403e8b7b750a804d9b69",
            "fa42d92fe8424c06a90c222700aa2f30",
            "34cdcb87238140748f6ec290e2ffee1b",
            "f7a67e2ecb014bbdb5e418f4d9a5f5c3",
            "aea44c20bff040e787504e8140e98d21",
            "b53ede5a55184d15a1cccfe7bea084dc",
            "7d3feea767f644e5bc81fca23f046781",
            "c4cb993eee254490bdeabef8d5fb2068",
            "9475c69229bf4ff28a2b9201b4e26880",
            "6d574b6472004461843bb0fa78bbe6e8",
            "07e78b7ea7ab4228835d0117417b40f6",
            "80329e814da541a2ac2cf0a0cd670243",
            "67fe3978b0e341e0887dfc41b3f9a57c",
            "8c448fca08dd4885b96b59282813fe26",
            "5ba78fda4510496ebf0b80890a979d13",
            "a0dd074825cc4fe4b2937df1d7db7704",
            "64cf14d872fe46f5b45b7e786f62905a",
            "de9b9a9b432841f6a7b16ecaba0f3a11",
            "f16850715e5846d2936bf8d19b239e9f",
            "5cc9000053d940d694815f4ebdb60fe7",
            "9e4e033783c44425ab944c2d28bbbaea",
            "94da18c3a00244b1a94e2e93b71d6f80",
            "91adb3a2949d4f2ca968ddd883a5e760",
            "ad27643b4cb84b5d9ec45b46e3cc233c",
            "3e2987a761d345f6a234e2830c8a8b12",
            "f41236b024614d059a4e36796088ab78",
            "94d3240ca44e4c26b6944c3c26101227",
            "e9ab502c3d8e4a3e9ad279ee087ee89e",
            "998a48779586445b9d69824307b822e1",
            "42b7ffd866104139b231dde94c182b6f",
            "86a7edbce19c4416869e99a7a9fb7071",
            "9b893ea794074486b9026da98a6f240c",
            "d8efe1d62c5440b5a370d8c75b5a9d86",
            "713e810077f54b85bb45b107c139a9dd",
            "ba980f76b13d47c694fbb799c199d1ac",
            "25fcaf1a537b48a098c61e58aaf8ce9a",
            "6c93ca27da844a389f850c2132dbb90e",
            "99a65fce944445abad1a2b021337896a",
            "525e38d7e3854ec19603949debe0a67a",
            "211b5b6957744b94bf2d08a9f49912c0",
            "39bba0202144447998b90ebe3773b7bd",
            "52644a667258412bb781c7b84b203dc5",
            "efc131b100d64185a4605e0eeb9c6ee9",
            "2ae0374131a94a15b4b0cb7f9462dae5",
            "cdb8652047c34782aa23043f3cd04f95",
            "cc778b2898c94e3c8920eaff7c84c2c4",
            "77614c33d2b542c6a52bc1fb2c37a75f",
            "ba6aa618936a418599780c5df7f42b2a",
            "b21a6fea3077415ebb885df6add1802f",
            "a03bcb242c2644d4a39c79c9151da732",
            "370e3a4342a944ad96c779ac9b4e14ef",
            "75bb1ea043474c6f9683c188017c9997",
            "508e7ca51fe04f46b10ee763c41bc5ae",
            "bf3c25eefeb74594a0859c88f1fd0fc9",
            "afef793285d0432cab056daaad036e75",
            "7a0b1e443d724146a81b040c7a641e99",
            "87e7a117a1264132a32ac004881f9182",
            "e78b54121be44448abc9d96cbb82de17",
            "f9581141305f442997ade35b88150e34",
            "53b36eb75c0d4f6b974d7cdd78bdeb28",
            "d720310e84ef40faabf7daf8cf23f975",
            "ea3503d2741c4d0d9ce0db2402859f2c",
            "02355254527649368ca5d827a5a32d64",
            "5704b6b0ff814a27a961886d3cecd6f2",
            "a8e9f410b32c46c1a8f6d0b6f3ef1946",
            "b1fdd7bbbd534882a568110fc6fb489e"
          ]
        },
        "id": "R3CAgoUeRVLa",
        "outputId": "39554d36-42f1-41f0-fa05-7659ba5a6c04"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-23-3405431599.py:2: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
            "  embedding_function = SentenceTransformerEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "942653e57d0147c1820313e10c2d4195"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "82910528cb7640b986101f77dd2f0ef9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "617c17d270a2472381227c064ddba078"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c5c287fef9c146cbb1da4111eeaae297"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8afb980d3c3946dbb21f5c6cb23c9fef"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d4720bacfa7b403e8b7b750a804d9b69"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "80329e814da541a2ac2cf0a0cd670243"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "91adb3a2949d4f2ca968ddd883a5e760"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "713e810077f54b85bb45b107c139a9dd"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cdb8652047c34782aa23043f3cd04f95"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7a0b1e443d724146a81b040c7a641e99"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Embedding Validation ---\n",
            "Number of original chunks: 34743\n",
            "Number of successfully embedded chunks: 34743\n",
            "All chunks successfully embedded.\n",
            "Type of first embedding: <class 'list'>\n",
            "Dimension of first embedding: 384\n",
            "First 10 values: [-0.09975712  0.09495571 -0.00870426 -0.01502324  0.02987907  0.00238186\n",
            "  0.09052261  0.07808921  0.02423851  0.00751337]\n"
          ]
        }
      ],
      "source": [
        "# Note: For M4 with 16GB RAM, process chunks in small batches to avoid memory issues.\n",
        "embedding_function = SentenceTransformerEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
        "\n",
        "# Embed chunks in batches\n",
        "embedded_chunks = []\n",
        "batch_size = 100  # Safe for 16GB RAM\n",
        "for i in range(0, len(chunks), batch_size):\n",
        "    batch = chunks[i:i+batch_size]\n",
        "    for j, chunk in enumerate(batch):\n",
        "        try:\n",
        "            embedding = embedding_function.embed_query(chunk.page_content)\n",
        "            embedded_chunks.append((chunk, embedding))\n",
        "        except Exception as e:\n",
        "            print(f\"Error embedding chunk {i+j}: {e}\")\n",
        "print(f\"\\n--- Embedding Validation ---\")\n",
        "print(f\"Number of original chunks: {len(chunks)}\")\n",
        "print(f\"Number of successfully embedded chunks: {len(embedded_chunks)}\")\n",
        "if len(embedded_chunks) == len(chunks):\n",
        "    print(\"All chunks successfully embedded.\")\n",
        "else:\n",
        "    print(f\"Embedded {len(embedded_chunks)}/{len(chunks)} chunks.\")\n",
        "\n",
        "if len(embedded_chunks) > 0:\n",
        "    first_embedded_chunk, first_embedding = embedded_chunks[0]\n",
        "    print(f\"Type of first embedding: {type(first_embedding)}\")\n",
        "    import numpy as np\n",
        "    first_embedding_np = np.array(first_embedding)\n",
        "    print(f\"Dimension of first embedding: {len(first_embedding_np)}\")\n",
        "    print(f\"First 10 values: {first_embedding_np[:10]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qiKCOv4X0d7B"
      },
      "source": [
        "### Vector Database"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vHHt1MQQRVzs",
        "outputId": "103687b2-ee4c-4e16-a501-5fb410f9f6ac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created directory at medical_db\n",
            "\n",
            "--- Vector Database Validation ---\n",
            "Chroma database created at medical_db.\n",
            "Number of items in database: 34743\n",
            "Match with embedded chunks.\n"
          ]
        }
      ],
      "source": [
        "#Vector Database\n",
        "import os, shutil\n",
        "\n",
        "from langchain_community.vectorstores import Chroma\n",
        "\n",
        "persist_directory = 'medical_db'\n",
        "if os.path.exists(persist_directory):\n",
        "    print(f\"Removing existing database at {persist_directory}\")\n",
        "    shutil.rmtree(persist_directory, ignore_errors=True)\n",
        "\n",
        "if not os.path.exists(persist_directory):\n",
        "    os.makedirs(persist_directory)\n",
        "    print(f\"Created directory at {persist_directory}\")\n",
        "\n",
        "try:\n",
        "    vector_db = Chroma.from_documents(\n",
        "        documents=[chunk for chunk, embedding in embedded_chunks],\n",
        "        embedding=embedding_function,\n",
        "        persist_directory=persist_directory\n",
        "    )\n",
        "except Exception as e:\n",
        "    print(f\"Error creating Chroma database: {e}\")\n",
        "    raise\n",
        "\n",
        "# Simplified vector database validation\n",
        "print(f\"\\n--- Vector Database Validation ---\")\n",
        "if os.path.exists(persist_directory):\n",
        "    print(f\"Chroma database created at {persist_directory}.\")\n",
        "try:\n",
        "    count = vector_db._collection.count()\n",
        "    print(f\"Number of items in database: {count}\")\n",
        "    print(\"Match with embedded chunks.\" if count == len(embedded_chunks) else \"Item count mismatch.\")\n",
        "except Exception as e:\n",
        "    print(f\"Error retrieving database count: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uEa5sKc41T1z"
      },
      "source": [
        "### Retriever"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wBlQUGx3RWUD",
        "outputId": "fef55003-a7cc-4272-ec5a-ccf8a87ab608"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Retriever Validation ---\n",
            "Conclusion: Retriever successfully created.\n",
            "\n",
            "Retrieved 3 documents for a sample query.\n",
            "Sample of retrieved document content (first 100 chars):\n",
            "Symptoms and Signs\n",
            "The classic symptoms of acute appendicitis are epigastric or periumbilical pain f...\n",
            "\n",
            "Retriever configuration:\n",
            "Search type: similarity\n",
            "Search kwargs: {'k': 3}\n",
            "Conclusion: Retriever configured with correct k value (3).\n"
          ]
        }
      ],
      "source": [
        "# prompt: code a retriever using the above code with the appropriate search method and k value\n",
        "retriever = vector_db.as_retriever(\n",
        "    search_type=\"similarity\",  # Using similarity search\n",
        "    search_kwargs={\"k\": 3}     # Retrieve top 3 similar documents\n",
        ")\n",
        "\n",
        "# --- Validation and Conclusions ---\n",
        "print(f\"\\n--- Retriever Validation ---\")\n",
        "if retriever:\n",
        "    print(\"Conclusion: Retriever successfully created.\")\n",
        "    try:\n",
        "        # Test with queries from problem statement (e.g., sepsis, appendicitis, hair loss)\n",
        "        sample_query = \"What are the symptoms of appendicitis?\"\n",
        "        retrieved_docs = retriever.invoke(sample_query)\n",
        "        print(f\"\\nRetrieved {len(retrieved_docs)} documents for a sample query.\")\n",
        "        if len(retrieved_docs) > 0:\n",
        "            print(\"Sample of retrieved document content (first 100 chars):\")\n",
        "            print(retrieved_docs[0].page_content[:100] + \"...\")\n",
        "        else:\n",
        "            print(\"No documents retrieved. Check vector database content or query relevance.\")\n",
        "\n",
        "        print(f\"\\nRetriever configuration:\")\n",
        "        print(f\"Search type: {retriever.search_type}\")\n",
        "        print(f\"Search kwargs: {retriever.search_kwargs}\")\n",
        "        if retriever.search_kwargs.get(\"k\") == 3:\n",
        "            print(\"Conclusion: Retriever configured with correct k value (3).\")\n",
        "        else:\n",
        "            print(f\"Warning: Retriever's k value is {retriever.search_kwargs.get('k')}, expected 3.\")\n",
        "    except ValueError as ve:\n",
        "        print(f\"Database error during retrieval: {ve}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error during sample query with retriever: {e}\")\n",
        "        print(\"Conclusion: Retriever might not be configured correctly or database has issues.\")\n",
        "else:\n",
        "    print(\"Conclusion: Failed to create the retriever.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vw8qcwq66B0C",
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "### System and User Prompt Template"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SSJhTwkDOWg3"
      },
      "outputs": [],
      "source": [
        "## 1. The system message describing the assistant's role.\n",
        "## 2. A user message template including context and the question."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M2k9pj_wqXkb"
      },
      "outputs": [],
      "source": [
        "# --- System and User Prompts ---\n",
        "qna_system_message = \"You are a knowledgeable medical assistant. Provide accurate, concise answers based solely on the provided context from the Merck Manuals. If the context is insufficient, state that you lack information.\"\n",
        "qna_user_message_template = \"\"\"Context: {context}\\n\\nQuestion: {question}\\nAnswer concisely and factually.\"\"\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ENTy5G5aqXkb"
      },
      "outputs": [],
      "source": [
        "# --- Evaluation Prompts ---\n",
        "groundedness_rater_system_message = \"You are an evaluator assessing the groundedness of a medical response. Rate the response based on whether all factual claims are supported by the provided context, on a scale of 1–5 (1: contradicts context, 5: fully supported). Return only the numeric rating.\"\n",
        "relevance_rater_system_message = \"You are an evaluator assessing the relevance of a medical response. Rate the response based on how directly it addresses the question, on a scale of 1–5 (1: irrelevant, 5: fully relevant). Return only the numeric rating.\"\n",
        "user_message_template = \"\"\"Question: {question}\\nResponse: {answer}\\nContext: {context}\\nRating:\"\"\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XlMR7AwkqXkc"
      },
      "outputs": [],
      "source": [
        "# --- Queries to Test ---\n",
        "queries_to_test = {\n",
        "    \"Query 1\": \"What is the protocol for managing sepsis in a critical care unit?\",\n",
        "    \"Query 2\": \"What are the common symptoms for appendicitis, and can it be cured via medicine? If not, what surgical procedure should be followed to treat it?\",\n",
        "    \"Query 3\": \"What are the effective treatments or solutions for addressing sudden patchy hair loss, commonly seen as localized bald spots on the scalp, and what could be the possible causes behind it?\",\n",
        "    \"Query 4\": \"What treatments are recommended for a person who has sustained a physical injury to brain tissue, resulting in temporary or permanent impairment of brain function?\",\n",
        "    \"Query 5\": \"What are the necessary precautions and treatment steps for a person who has fractured their leg during a hiking trip, and what should be considered for their care and recovery?\"\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TmzokxmeqXkc"
      },
      "outputs": [],
      "source": [
        "# --- RAG Response Function ---\n",
        "def generate_rag_response(user_input, retriever, max_tokens=128, temperature=0, top_p=0.95, top_k=50):\n",
        "    global qna_system_message, qna_user_message_template\n",
        "    try:\n",
        "        relevant_document_chunks = retriever.invoke(user_input)\n",
        "        context_list = [d.page_content for d in relevant_document_chunks]\n",
        "        context_for_query = \". \".join(context_list)[:4000]  # Limit for M4\n",
        "        user_message = qna_user_message_template.replace('{context}', context_for_query).replace('{question}', user_input)\n",
        "        prompt = f\"{qna_system_message}\\n{user_message}\".strip()\n",
        "        response = llm(\n",
        "            prompt=prompt,\n",
        "            max_tokens=max_tokens,\n",
        "            temperature=temperature,\n",
        "            top_p=top_p,\n",
        "            top_k=top_k\n",
        "        )\n",
        "        return response['choices'][0]['text'].strip(), context_for_query\n",
        "    except ValueError as ve:\n",
        "        return f\"Retrieval error: {ve}\", \"\"\n",
        "    except Exception as e:\n",
        "        return f\"Sorry, I encountered the following error: {e}\", \"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QPybF1xbqXkd"
      },
      "outputs": [],
      "source": [
        "# --- Groundedness and Relevance Evaluation Function ---\n",
        "def generate_ground_relevance_response(user_input, retriever, max_tokens=10, temperature=0, top_p=0.95, top_k=50):\n",
        "    global groundedness_rater_system_message, relevance_rater_system_message, user_message_template\n",
        "    try:\n",
        "        # Generate RAG response and get context\n",
        "        answer, context_for_query = generate_rag_response(user_input, retriever, max_tokens=128, temperature=0)\n",
        "\n",
        "        # Groundedness evaluation\n",
        "        groundedness_prompt = user_message_template.format(\n",
        "            question=user_input,\n",
        "            answer=answer,\n",
        "            context=context_for_query\n",
        "        )\n",
        "        groundedness_response = llm(\n",
        "            prompt=f\"{groundedness_rater_system_message}\\n{groundedness_prompt}\",\n",
        "            max_tokens=max_tokens,\n",
        "            temperature=temperature,\n",
        "            top_p=top_p,\n",
        "            top_k=top_k\n",
        "        )\n",
        "        groundedness_rating = groundedness_response['choices'][0]['text'].strip()\n",
        "\n",
        "        # Relevance evaluation\n",
        "        relevance_prompt = user_message_template.format(\n",
        "            question=user_input,\n",
        "            answer=answer,\n",
        "            context=context_for_query\n",
        "        )\n",
        "        relevance_response = llm(\n",
        "            prompt=f\"{relevance_rater_system_message}\\n{relevance_prompt}\",\n",
        "            max_tokens=max_tokens,\n",
        "            temperature=temperature,\n",
        "            top_p=top_p,\n",
        "            top_k=top_k\n",
        "        )\n",
        "        relevance_rating = relevance_response['choices'][0]['text'].strip()\n",
        "\n",
        "        return groundedness_rating, relevance_rating, answer, context_for_query\n",
        "    except Exception as e:\n",
        "        return f\"Error: {e}\", f\"Error: {e}\", \"\", \"\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qjhDHfk_qXkd"
      },
      "outputs": [],
      "source": [
        "# --- Fine-tuning Parameters ---\n",
        "param_combinations = [\n",
        "    {\"chunk_size\": 500, \"chunk_overlap\": 100, \"retriever_k\": 3, \"llm_max_tokens\": 128, \"llm_temperature\": 0},\n",
        "    {\"chunk_size\": 750, \"chunk_overlap\": 150, \"retriever_k\": 5, \"llm_max_tokens\": 200, \"llm_temperature\": 0.1},\n",
        "    {\"chunk_size\": 1000, \"chunk_overlap\": 200, \"retriever_k\": 3, \"llm_max_tokens\": 128, \"llm_temperature\": 0},\n",
        "    {\"chunk_size\": 500, \"chunk_overlap\": 100, \"retriever_k\": 5, \"llm_max_tokens\": 200, \"llm_temperature\": 0.2},\n",
        "    {\"chunk_size\": 750, \"chunk_overlap\": 150, \"retriever_k\": 3, \"llm_max_tokens\": 128, \"llm_temperature\": 0.1}\n",
        "]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pEJR2esqqXkd",
        "outputId": "69e2ea68-7e78-4a88-ba69-f608305d97ba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Fine-tuning RAG Parameters ---\n",
            "\n",
            "--- Combination 1: {'chunk_size': 500, 'chunk_overlap': 100, 'retriever_k': 3, 'llm_max_tokens': 128, 'llm_temperature': 0} ---\n",
            "  Created 34743 chunks.\n",
            "  Embedded 34743 chunks.\n",
            "  Retriever created with k=3\n",
            "    Testing Query: Query 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: 4 prefix-match hit, remaining 400 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    1484.88 ms\n",
            "llama_perf_context_print: prompt eval time =   29720.61 ms /   400 tokens (   74.30 ms per token,    13.46 tokens per second)\n",
            "llama_perf_context_print:        eval time =   13778.35 ms /    84 runs   (  164.03 ms per token,     6.10 tokens per second)\n",
            "llama_perf_context_print:       total time =   43544.44 ms /   484 tokens\n",
            "Llama.generate: 3 prefix-match hit, remaining 502 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    1484.88 ms\n",
            "llama_perf_context_print: prompt eval time =   38130.68 ms /   502 tokens (   75.96 ms per token,    13.17 tokens per second)\n",
            "llama_perf_context_print:        eval time =    1523.76 ms /     9 runs   (  169.31 ms per token,     5.91 tokens per second)\n",
            "llama_perf_context_print:       total time =   39659.33 ms /   511 tokens\n",
            "Llama.generate: 9 prefix-match hit, remaining 488 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    1484.88 ms\n",
            "llama_perf_context_print: prompt eval time =   36170.30 ms /   488 tokens (   74.12 ms per token,    13.49 tokens per second)\n",
            "llama_perf_context_print:        eval time =     331.56 ms /     2 runs   (  165.78 ms per token,     6.03 tokens per second)\n",
            "llama_perf_context_print:       total time =   36503.65 ms /   490 tokens\n",
            "Llama.generate: 3 prefix-match hit, remaining 469 prompt tokens to eval\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    Response: The protocol for managing sepsis in a critical care unit includes controlling hemorrhage, checking and providing respiratory assistance if necessary, keeping the patient warm, avoiding anything by mou...\n",
            "    Groundedness Rating: 5. The response is fully supported by the\n",
            "    Relevance Rating: 5\n",
            "    Testing Query: Query 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "llama_perf_context_print:        load time =    1484.88 ms\n",
            "llama_perf_context_print: prompt eval time =   35325.21 ms /   469 tokens (   75.32 ms per token,    13.28 tokens per second)\n",
            "llama_perf_context_print:        eval time =   20861.03 ms /   127 runs   (  164.26 ms per token,     6.09 tokens per second)\n",
            "llama_perf_context_print:       total time =   56256.94 ms /   596 tokens\n",
            "Llama.generate: 3 prefix-match hit, remaining 614 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    1484.88 ms\n",
            "llama_perf_context_print: prompt eval time =   46081.01 ms /   614 tokens (   75.05 ms per token,    13.32 tokens per second)\n",
            "llama_perf_context_print:        eval time =    1461.31 ms /     9 runs   (  162.37 ms per token,     6.16 tokens per second)\n",
            "llama_perf_context_print:       total time =   47547.13 ms /   623 tokens\n",
            "Llama.generate: 9 prefix-match hit, remaining 600 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    1484.88 ms\n",
            "llama_perf_context_print: prompt eval time =   46561.89 ms /   600 tokens (   77.60 ms per token,    12.89 tokens per second)\n",
            "llama_perf_context_print:        eval time =     327.66 ms /     2 runs   (  163.83 ms per token,     6.10 tokens per second)\n",
            "llama_perf_context_print:       total time =   46891.40 ms /   602 tokens\n",
            "Llama.generate: 3 prefix-match hit, remaining 453 prompt tokens to eval\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    Response: The common symptoms for appendicitis include epigastric or periumbilical pain followed by brief nausea, vomiting, and anorexia, which later shifts to the right lower quadrant. The pain increases with ...\n",
            "    Groundedness Rating: 5. The response accurately describes the common symptoms\n",
            "    Relevance Rating: 5\n",
            "    Testing Query: Query 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "llama_perf_context_print:        load time =    1484.88 ms\n",
            "llama_perf_context_print: prompt eval time =   33369.21 ms /   453 tokens (   73.66 ms per token,    13.58 tokens per second)\n",
            "llama_perf_context_print:        eval time =   20706.46 ms /   127 runs   (  163.04 ms per token,     6.13 tokens per second)\n",
            "llama_perf_context_print:       total time =   54146.87 ms /   580 tokens\n",
            "Llama.generate: 3 prefix-match hit, remaining 598 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    1484.88 ms\n",
            "llama_perf_context_print: prompt eval time =   44715.53 ms /   598 tokens (   74.78 ms per token,    13.37 tokens per second)\n",
            "llama_perf_context_print:        eval time =    1470.25 ms /     9 runs   (  163.36 ms per token,     6.12 tokens per second)\n",
            "llama_perf_context_print:       total time =   46190.70 ms /   607 tokens\n",
            "Llama.generate: 9 prefix-match hit, remaining 584 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    1484.88 ms\n",
            "llama_perf_context_print: prompt eval time =   45483.43 ms /   584 tokens (   77.88 ms per token,    12.84 tokens per second)\n",
            "llama_perf_context_print:        eval time =     331.57 ms /     2 runs   (  165.79 ms per token,     6.03 tokens per second)\n",
            "llama_perf_context_print:       total time =   45816.99 ms /   586 tokens\n",
            "Llama.generate: 3 prefix-match hit, remaining 423 prompt tokens to eval\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    Response: Alopecia areata is a type of nonscarring alopecia characterized by sudden, patchy hair loss. The scalp and beard are most commonly affected, but any hairy area can be involved. The cause is not clear,...\n",
            "    Groundedness Rating: 5\n",
            "The response accurately identifies alo\n",
            "    Relevance Rating: 5\n",
            "    Testing Query: Query 4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "llama_perf_context_print:        load time =    1484.88 ms\n",
            "llama_perf_context_print: prompt eval time =   31566.79 ms /   423 tokens (   74.63 ms per token,    13.40 tokens per second)\n",
            "llama_perf_context_print:        eval time =   20751.78 ms /   127 runs   (  163.40 ms per token,     6.12 tokens per second)\n",
            "llama_perf_context_print:       total time =   52391.26 ms /   550 tokens\n",
            "Llama.generate: 3 prefix-match hit, remaining 568 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    1484.88 ms\n",
            "llama_perf_context_print: prompt eval time =   42525.46 ms /   568 tokens (   74.87 ms per token,    13.36 tokens per second)\n",
            "llama_perf_context_print:        eval time =    1467.25 ms /     9 runs   (  163.03 ms per token,     6.13 tokens per second)\n",
            "llama_perf_context_print:       total time =   43997.58 ms /   577 tokens\n",
            "Llama.generate: 9 prefix-match hit, remaining 554 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    1484.88 ms\n",
            "llama_perf_context_print: prompt eval time =   41961.11 ms /   554 tokens (   75.74 ms per token,    13.20 tokens per second)\n",
            "llama_perf_context_print:        eval time =    1504.66 ms /     9 runs   (  167.18 ms per token,     5.98 tokens per second)\n",
            "llama_perf_context_print:       total time =   43470.83 ms /   563 tokens\n",
            "Llama.generate: 3 prefix-match hit, remaining 502 prompt tokens to eval\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    Response: Use only the information provided in the context.\n",
            "\n",
            "The Merck Manual suggests a team approach to treating brain injury that includes physical, occupational, and speech therapy, skill-building activitie...\n",
            "    Groundedness Rating: 5. The response accurately reflects the context,\n",
            "    Relevance Rating: 5. The response directly addresses the question by\n",
            "    Testing Query: Query 5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "llama_perf_context_print:        load time =    1484.88 ms\n",
            "llama_perf_context_print: prompt eval time =   37163.01 ms /   502 tokens (   74.03 ms per token,    13.51 tokens per second)\n",
            "llama_perf_context_print:        eval time =   20774.36 ms /   127 runs   (  163.58 ms per token,     6.11 tokens per second)\n",
            "llama_perf_context_print:       total time =   58009.50 ms /   629 tokens\n",
            "Llama.generate: 3 prefix-match hit, remaining 647 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    1484.88 ms\n",
            "llama_perf_context_print: prompt eval time =   48878.02 ms /   647 tokens (   75.55 ms per token,    13.24 tokens per second)\n",
            "llama_perf_context_print:        eval time =    1470.87 ms /     9 runs   (  163.43 ms per token,     6.12 tokens per second)\n",
            "llama_perf_context_print:       total time =   50353.73 ms /   656 tokens\n",
            "Llama.generate: 9 prefix-match hit, remaining 633 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    1484.88 ms\n",
            "llama_perf_context_print: prompt eval time =   47642.80 ms /   633 tokens (   75.27 ms per token,    13.29 tokens per second)\n",
            "llama_perf_context_print:        eval time =     336.32 ms /     2 runs   (  168.16 ms per token,     5.95 tokens per second)\n",
            "llama_perf_context_print:       total time =   47981.04 ms /   635 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    Response: Based on the context provided, a femoral shaft fracture is a serious injury that requires immediate medical attention. The usual treatment is open reduction and internal fixation (ORIF) and early mobi...\n",
            "    Groundedness Rating: 5. The response accurately reflects the context provided\n",
            "    Relevance Rating: 5\n",
            "\n",
            "--- Combination 2: {'chunk_size': 750, 'chunk_overlap': 150, 'retriever_k': 5, 'llm_max_tokens': 200, 'llm_temperature': 0.1} ---\n",
            "  Created 23993 chunks.\n",
            "  Embedded 23993 chunks.\n",
            "  Retriever created with k=5\n",
            "    Testing Query: Query 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: 3 prefix-match hit, remaining 1105 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    1484.88 ms\n",
            "llama_perf_context_print: prompt eval time =   84062.38 ms /  1105 tokens (   76.07 ms per token,    13.15 tokens per second)\n",
            "llama_perf_context_print:        eval time =   21518.64 ms /   127 runs   (  169.44 ms per token,     5.90 tokens per second)\n",
            "llama_perf_context_print:       total time =  105654.61 ms /  1232 tokens\n",
            "Llama.generate: 3 prefix-match hit, remaining 1250 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    1484.88 ms\n",
            "llama_perf_context_print: prompt eval time =   95204.48 ms /  1250 tokens (   76.16 ms per token,    13.13 tokens per second)\n",
            "llama_perf_context_print:        eval time =    1505.94 ms /     9 runs   (  167.33 ms per token,     5.98 tokens per second)\n",
            "llama_perf_context_print:       total time =   96715.57 ms /  1259 tokens\n",
            "Llama.generate: 9 prefix-match hit, remaining 1236 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    1484.88 ms\n",
            "llama_perf_context_print: prompt eval time =   94760.56 ms /  1236 tokens (   76.67 ms per token,    13.04 tokens per second)\n",
            "llama_perf_context_print:        eval time =     348.77 ms /     2 runs   (  174.38 ms per token,     5.73 tokens per second)\n",
            "llama_perf_context_print:       total time =   95111.45 ms /  1238 tokens\n",
            "Llama.generate: 3 prefix-match hit, remaining 1043 prompt tokens to eval\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    Response: The protocol for managing sepsis in a critical care unit includes aggressive fluid resuscitation, antibiotics, surgical excision of infected or necrotic tissues and drainage of pus, supportive care, a...\n",
            "    Groundedness Rating: 5. The response accurately describes the protocol for\n",
            "    Relevance Rating: 5\n",
            "    Testing Query: Query 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "llama_perf_context_print:        load time =    1484.88 ms\n",
            "llama_perf_context_print: prompt eval time =   78922.69 ms /  1043 tokens (   75.67 ms per token,    13.22 tokens per second)\n",
            "llama_perf_context_print:        eval time =   21365.71 ms /   127 runs   (  168.23 ms per token,     5.94 tokens per second)\n",
            "llama_perf_context_print:       total time =  100360.80 ms /  1170 tokens\n",
            "Llama.generate: 3 prefix-match hit, remaining 1188 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    1484.88 ms\n",
            "llama_perf_context_print: prompt eval time =   90519.48 ms /  1188 tokens (   76.19 ms per token,    13.12 tokens per second)\n",
            "llama_perf_context_print:        eval time =    1493.08 ms /     9 runs   (  165.90 ms per token,     6.03 tokens per second)\n",
            "llama_perf_context_print:       total time =   92017.66 ms /  1197 tokens\n",
            "Llama.generate: 9 prefix-match hit, remaining 1174 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    1484.88 ms\n",
            "llama_perf_context_print: prompt eval time =   91056.39 ms /  1174 tokens (   77.56 ms per token,    12.89 tokens per second)\n",
            "llama_perf_context_print:        eval time =    1492.62 ms /     9 runs   (  165.85 ms per token,     6.03 tokens per second)\n",
            "llama_perf_context_print:       total time =   92554.20 ms /  1183 tokens\n",
            "Llama.generate: 3 prefix-match hit, remaining 1048 prompt tokens to eval\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    Response: Do not use I or we.\n",
            "\n",
            "The common symptoms of appendicitis include epigastric or periumbilical pain followed by brief nausea, vomiting, and anorexia, which later shifts to the right lower quadrant. Pain...\n",
            "    Groundedness Rating: 5\n",
            "All factual claims are fully supported\n",
            "    Relevance Rating: 5\n",
            "The response directly addresses the question by\n",
            "    Testing Query: Query 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "llama_perf_context_print:        load time =    1484.88 ms\n",
            "llama_perf_context_print: prompt eval time =   79688.84 ms /  1048 tokens (   76.04 ms per token,    13.15 tokens per second)\n",
            "llama_perf_context_print:        eval time =   21109.91 ms /   127 runs   (  166.22 ms per token,     6.02 tokens per second)\n",
            "llama_perf_context_print:       total time =  100869.21 ms /  1175 tokens\n",
            "Llama.generate: 3 prefix-match hit, remaining 1193 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    1484.88 ms\n",
            "llama_perf_context_print: prompt eval time =   91611.51 ms /  1193 tokens (   76.79 ms per token,    13.02 tokens per second)\n",
            "llama_perf_context_print:        eval time =    1501.81 ms /     9 runs   (  166.87 ms per token,     5.99 tokens per second)\n",
            "llama_perf_context_print:       total time =   93118.45 ms /  1202 tokens\n",
            "Llama.generate: 9 prefix-match hit, remaining 1179 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    1484.88 ms\n",
            "llama_perf_context_print: prompt eval time =   91054.98 ms /  1179 tokens (   77.23 ms per token,    12.95 tokens per second)\n",
            "llama_perf_context_print:        eval time =    1493.25 ms /     9 runs   (  165.92 ms per token,     6.03 tokens per second)\n",
            "llama_perf_context_print:       total time =   92553.39 ms /  1188 tokens\n",
            "Llama.generate: 3 prefix-match hit, remaining 947 prompt tokens to eval\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    Response: Androgenetic alopecia is the most common cause of hair loss, but sudden patchy hair loss, also known as alopecia areata, is a different condition. Alopecia areata is an autoimmune disorder affecting g...\n",
            "    Groundedness Rating: 5. All factual claims are fully supported\n",
            "    Relevance Rating: 5. The response directly addresses the question by\n",
            "    Testing Query: Query 4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "llama_perf_context_print:        load time =    1484.88 ms\n",
            "llama_perf_context_print: prompt eval time =   72490.69 ms /   947 tokens (   76.55 ms per token,    13.06 tokens per second)\n",
            "llama_perf_context_print:        eval time =   21048.88 ms /   127 runs   (  165.74 ms per token,     6.03 tokens per second)\n",
            "llama_perf_context_print:       total time =   93610.51 ms /  1074 tokens\n",
            "Llama.generate: 3 prefix-match hit, remaining 1092 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    1484.88 ms\n",
            "llama_perf_context_print: prompt eval time =   84447.13 ms /  1092 tokens (   77.33 ms per token,    12.93 tokens per second)\n",
            "llama_perf_context_print:        eval time =    1499.75 ms /     9 runs   (  166.64 ms per token,     6.00 tokens per second)\n",
            "llama_perf_context_print:       total time =   85952.34 ms /  1101 tokens\n",
            "Llama.generate: 9 prefix-match hit, remaining 1078 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    1484.88 ms\n",
            "llama_perf_context_print: prompt eval time =   81809.72 ms /  1078 tokens (   75.89 ms per token,    13.18 tokens per second)\n",
            "llama_perf_context_print:        eval time =    1513.75 ms /     9 runs   (  168.19 ms per token,     5.95 tokens per second)\n",
            "llama_perf_context_print:       total time =   83328.54 ms /  1087 tokens\n",
            "Llama.generate: 3 prefix-match hit, remaining 977 prompt tokens to eval\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    Response: Do not offer opinions or speculate.\n",
            "\n",
            "Answer: For a person with a brain injury resulting in neurologic deficits, rehabilitation is necessary. This typically involves a team approach combining physical,...\n",
            "    Groundedness Rating: 5. The response accurately reflects the context,\n",
            "    Relevance Rating: 5. The response directly addresses the question by\n",
            "    Testing Query: Query 5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "llama_perf_context_print:        load time =    1484.88 ms\n",
            "llama_perf_context_print: prompt eval time =   75379.18 ms /   977 tokens (   77.15 ms per token,    12.96 tokens per second)\n",
            "llama_perf_context_print:        eval time =   21118.29 ms /   127 runs   (  166.29 ms per token,     6.01 tokens per second)\n",
            "llama_perf_context_print:       total time =   96569.89 ms /  1104 tokens\n",
            "Llama.generate: 3 prefix-match hit, remaining 1122 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    1484.88 ms\n",
            "llama_perf_context_print: prompt eval time =   86724.49 ms /  1122 tokens (   77.29 ms per token,    12.94 tokens per second)\n",
            "llama_perf_context_print:        eval time =    1526.43 ms /     9 runs   (  169.60 ms per token,     5.90 tokens per second)\n",
            "llama_perf_context_print:       total time =   88256.41 ms /  1131 tokens\n",
            "Llama.generate: 9 prefix-match hit, remaining 1108 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    1484.88 ms\n",
            "llama_perf_context_print: prompt eval time =   87893.71 ms /  1108 tokens (   79.33 ms per token,    12.61 tokens per second)\n",
            "llama_perf_context_print:        eval time =     340.84 ms /     2 runs   (  170.42 ms per token,     5.87 tokens per second)\n",
            "llama_perf_context_print:       total time =   88236.58 ms /  1110 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    Response: Based on the context provided, the person has sustained a fracture, likely in their leg. The Merck Manual suggests initial treatment includes rest, ice, compression, and elevation (RICE). Depending on...\n",
            "    Groundedness Rating: 5\n",
            "All factual claims are fully supported\n",
            "    Relevance Rating: 5\n",
            "\n",
            "--- Combination 3: {'chunk_size': 1000, 'chunk_overlap': 200, 'retriever_k': 3, 'llm_max_tokens': 128, 'llm_temperature': 0} ---\n",
            "  Created 18124 chunks.\n",
            "  Embedded 18124 chunks.\n",
            "  Retriever created with k=3\n",
            "    Testing Query: Query 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: 3 prefix-match hit, remaining 799 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    1484.88 ms\n",
            "llama_perf_context_print: prompt eval time =   60724.79 ms /   799 tokens (   76.00 ms per token,    13.16 tokens per second)\n",
            "llama_perf_context_print:        eval time =   20915.73 ms /   127 runs   (  164.69 ms per token,     6.07 tokens per second)\n",
            "llama_perf_context_print:       total time =   81712.49 ms /   926 tokens\n",
            "Llama.generate: 3 prefix-match hit, remaining 944 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    1484.88 ms\n",
            "llama_perf_context_print: prompt eval time =   71208.55 ms /   944 tokens (   75.43 ms per token,    13.26 tokens per second)\n",
            "llama_perf_context_print:        eval time =    1513.76 ms /     9 runs   (  168.20 ms per token,     5.95 tokens per second)\n",
            "llama_perf_context_print:       total time =   72727.68 ms /   953 tokens\n",
            "Llama.generate: 9 prefix-match hit, remaining 930 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    1484.88 ms\n",
            "llama_perf_context_print: prompt eval time =   70460.93 ms /   930 tokens (   75.76 ms per token,    13.20 tokens per second)\n",
            "llama_perf_context_print:        eval time =    1476.24 ms /     9 runs   (  164.03 ms per token,     6.10 tokens per second)\n",
            "llama_perf_context_print:       total time =   71942.27 ms /   939 tokens\n",
            "Llama.generate: 3 prefix-match hit, remaining 815 prompt tokens to eval\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    Response: Based on the provided context, the management of sepsis in a critical care unit involves the following steps:\n",
            "1. First aid: Keep the patient warm, control hemorrhage, check the airway and ventilation,...\n",
            "    Groundedness Rating: 7\n",
            "The response is fully supported by the\n",
            "    Relevance Rating: 7\n",
            "The response directly addresses the question by\n",
            "    Testing Query: Query 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "llama_perf_context_print:        load time =    1484.88 ms\n",
            "llama_perf_context_print: prompt eval time =   61732.51 ms /   815 tokens (   75.75 ms per token,    13.20 tokens per second)\n",
            "llama_perf_context_print:        eval time =   20133.05 ms /   121 runs   (  166.39 ms per token,     6.01 tokens per second)\n",
            "llama_perf_context_print:       total time =   81935.80 ms /   936 tokens\n",
            "Llama.generate: 3 prefix-match hit, remaining 953 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    1484.88 ms\n",
            "llama_perf_context_print: prompt eval time =   71717.60 ms /   953 tokens (   75.25 ms per token,    13.29 tokens per second)\n",
            "llama_perf_context_print:        eval time =    1486.61 ms /     9 runs   (  165.18 ms per token,     6.05 tokens per second)\n",
            "llama_perf_context_print:       total time =   73209.21 ms /   962 tokens\n",
            "Llama.generate: 9 prefix-match hit, remaining 939 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    1484.88 ms\n",
            "llama_perf_context_print: prompt eval time =   72591.31 ms /   939 tokens (   77.31 ms per token,    12.94 tokens per second)\n",
            "llama_perf_context_print:        eval time =     362.22 ms /     2 runs   (  181.11 ms per token,     5.52 tokens per second)\n",
            "llama_perf_context_print:       total time =   72955.74 ms /   941 tokens\n",
            "Llama.generate: 3 prefix-match hit, remaining 901 prompt tokens to eval\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    Response: Appendicitis is characterized by symptoms such as epigastric or periumbilical pain followed by brief nausea, vomiting, and anorexia, which later shifts to the right lower quadrant. Pain increases with...\n",
            "    Groundedness Rating: 5. All factual claims are fully supported\n",
            "    Relevance Rating: 5\n",
            "    Testing Query: Query 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "llama_perf_context_print:        load time =    1484.88 ms\n",
            "llama_perf_context_print: prompt eval time =   67758.67 ms /   901 tokens (   75.20 ms per token,    13.30 tokens per second)\n",
            "llama_perf_context_print:        eval time =   20989.02 ms /   127 runs   (  165.27 ms per token,     6.05 tokens per second)\n",
            "llama_perf_context_print:       total time =   88817.75 ms /  1028 tokens\n",
            "Llama.generate: 3 prefix-match hit, remaining 1046 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    1484.88 ms\n",
            "llama_perf_context_print: prompt eval time =   80182.19 ms /  1046 tokens (   76.66 ms per token,    13.05 tokens per second)\n",
            "llama_perf_context_print:        eval time =    1666.13 ms /     9 runs   (  185.13 ms per token,     5.40 tokens per second)\n",
            "llama_perf_context_print:       total time =   81853.49 ms /  1055 tokens\n",
            "Llama.generate: 9 prefix-match hit, remaining 1032 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    1484.88 ms\n",
            "llama_perf_context_print: prompt eval time =   78752.61 ms /  1032 tokens (   76.31 ms per token,    13.10 tokens per second)\n",
            "llama_perf_context_print:        eval time =    1545.08 ms /     9 runs   (  171.68 ms per token,     5.82 tokens per second)\n",
            "llama_perf_context_print:       total time =   80302.89 ms /  1041 tokens\n",
            "Llama.generate: 3 prefix-match hit, remaining 706 prompt tokens to eval\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    Response: Based on the context provided, the possible causes of sudden patchy hair loss could be alopecia areata, tinea capitis, trichotillomania, or scarring alopecia. The effective treatments for alopecia are...\n",
            "    Groundedness Rating: 5. The response fully supports the factual\n",
            "    Relevance Rating: 5\n",
            "The response directly addresses the question by\n",
            "    Testing Query: Query 4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "llama_perf_context_print:        load time =    1484.88 ms\n",
            "llama_perf_context_print: prompt eval time =   53774.83 ms /   706 tokens (   76.17 ms per token,    13.13 tokens per second)\n",
            "llama_perf_context_print:        eval time =   20809.31 ms /   127 runs   (  163.85 ms per token,     6.10 tokens per second)\n",
            "llama_perf_context_print:       total time =   74655.94 ms /   833 tokens\n",
            "Llama.generate: 3 prefix-match hit, remaining 851 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    1484.88 ms\n",
            "llama_perf_context_print: prompt eval time =   64257.03 ms /   851 tokens (   75.51 ms per token,    13.24 tokens per second)\n",
            "llama_perf_context_print:        eval time =    1479.80 ms /     9 runs   (  164.42 ms per token,     6.08 tokens per second)\n",
            "llama_perf_context_print:       total time =   65741.94 ms /   860 tokens\n",
            "Llama.generate: 9 prefix-match hit, remaining 837 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    1484.88 ms\n",
            "llama_perf_context_print: prompt eval time =   64347.78 ms /   837 tokens (   76.88 ms per token,    13.01 tokens per second)\n",
            "llama_perf_context_print:        eval time =     334.29 ms /     2 runs   (  167.14 ms per token,     5.98 tokens per second)\n",
            "llama_perf_context_print:       total time =   64684.09 ms /   839 tokens\n",
            "Llama.generate: 3 prefix-match hit, remaining 809 prompt tokens to eval\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    Response: Early intervention by rehabilitation specialists is crucial for maximal functional recovery. This includes prevention of secondary disabilities, such as pressure ulcers and joint contractures, prevent...\n",
            "    Groundedness Rating: 5. The response accurately reflects the context,\n",
            "    Relevance Rating: 5\n",
            "    Testing Query: Query 5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "llama_perf_context_print:        load time =    1484.88 ms\n",
            "llama_perf_context_print: prompt eval time =   60918.19 ms /   809 tokens (   75.30 ms per token,    13.28 tokens per second)\n",
            "llama_perf_context_print:        eval time =   20906.60 ms /   127 runs   (  164.62 ms per token,     6.07 tokens per second)\n",
            "llama_perf_context_print:       total time =   81895.86 ms /   936 tokens\n",
            "Llama.generate: 3 prefix-match hit, remaining 954 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    1484.88 ms\n",
            "llama_perf_context_print: prompt eval time =   72848.62 ms /   954 tokens (   76.36 ms per token,    13.10 tokens per second)\n",
            "llama_perf_context_print:        eval time =    1488.15 ms /     9 runs   (  165.35 ms per token,     6.05 tokens per second)\n",
            "llama_perf_context_print:       total time =   74341.94 ms /   963 tokens\n",
            "Llama.generate: 9 prefix-match hit, remaining 940 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    1484.88 ms\n",
            "llama_perf_context_print: prompt eval time =   70834.79 ms /   940 tokens (   75.36 ms per token,    13.27 tokens per second)\n",
            "llama_perf_context_print:        eval time =     380.69 ms /     2 runs   (  190.34 ms per token,     5.25 tokens per second)\n",
            "llama_perf_context_print:       total time =   71217.45 ms /   942 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    Response: The person with a fractured leg should be assessed for potential life-threatening complications such as rapid blood loss and fat embolism. If the fracture is open, keeping the limb off the ground and ...\n",
            "    Groundedness Rating: 5. The response accurately references the context,\n",
            "    Relevance Rating: 5\n",
            "\n",
            "--- Combination 4: {'chunk_size': 500, 'chunk_overlap': 100, 'retriever_k': 5, 'llm_max_tokens': 200, 'llm_temperature': 0.2} ---\n",
            "  Created 34743 chunks.\n",
            "  Embedded 34743 chunks.\n",
            "  Retriever created with k=5\n",
            "    Testing Query: Query 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: 3 prefix-match hit, remaining 656 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    1484.88 ms\n",
            "llama_perf_context_print: prompt eval time =   49660.73 ms /   656 tokens (   75.70 ms per token,    13.21 tokens per second)\n",
            "llama_perf_context_print:        eval time =   20761.76 ms /   127 runs   (  163.48 ms per token,     6.12 tokens per second)\n",
            "llama_perf_context_print:       total time =   70492.72 ms /   783 tokens\n",
            "Llama.generate: 3 prefix-match hit, remaining 801 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    1484.88 ms\n",
            "llama_perf_context_print: prompt eval time =   60974.54 ms /   801 tokens (   76.12 ms per token,    13.14 tokens per second)\n",
            "llama_perf_context_print:        eval time =    1467.97 ms /     9 runs   (  163.11 ms per token,     6.13 tokens per second)\n",
            "llama_perf_context_print:       total time =   62447.59 ms /   810 tokens\n",
            "Llama.generate: 9 prefix-match hit, remaining 787 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    1484.88 ms\n",
            "llama_perf_context_print: prompt eval time =   58854.07 ms /   787 tokens (   74.78 ms per token,    13.37 tokens per second)\n",
            "llama_perf_context_print:        eval time =     332.77 ms /     2 runs   (  166.39 ms per token,     6.01 tokens per second)\n",
            "llama_perf_context_print:       total time =   59188.87 ms /   789 tokens\n",
            "Llama.generate: 3 prefix-match hit, remaining 701 prompt tokens to eval\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    Response: Based on the context provided, the protocol for managing sepsis in a critical care unit includes the following steps:\n",
            "1. First aid: Keep the patient warm, control hemorrhage, check and assist airway a...\n",
            "    Groundedness Rating: 5\n",
            "Explanation: The response accurately\n",
            "    Relevance Rating: 5\n",
            "    Testing Query: Query 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "llama_perf_context_print:        load time =    1484.88 ms\n",
            "llama_perf_context_print: prompt eval time =   52782.33 ms /   701 tokens (   75.30 ms per token,    13.28 tokens per second)\n",
            "llama_perf_context_print:        eval time =   20987.38 ms /   127 runs   (  165.25 ms per token,     6.05 tokens per second)\n",
            "llama_perf_context_print:       total time =   73841.04 ms /   828 tokens\n",
            "Llama.generate: 3 prefix-match hit, remaining 846 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    1484.88 ms\n",
            "llama_perf_context_print: prompt eval time =   64249.51 ms /   846 tokens (   75.95 ms per token,    13.17 tokens per second)\n",
            "llama_perf_context_print:        eval time =    1483.39 ms /     9 runs   (  164.82 ms per token,     6.07 tokens per second)\n",
            "llama_perf_context_print:       total time =   65737.85 ms /   855 tokens\n",
            "Llama.generate: 9 prefix-match hit, remaining 832 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    1484.88 ms\n",
            "llama_perf_context_print: prompt eval time =   63140.75 ms /   832 tokens (   75.89 ms per token,    13.18 tokens per second)\n",
            "llama_perf_context_print:        eval time =    1490.97 ms /     9 runs   (  165.66 ms per token,     6.04 tokens per second)\n",
            "llama_perf_context_print:       total time =   64636.59 ms /   841 tokens\n",
            "Llama.generate: 3 prefix-match hit, remaining 690 prompt tokens to eval\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    Response: The common symptoms for appendicitis include epigastric or periumbilical pain followed by brief nausea, vomiting, and anorexia, which later shifts to the right lower quadrant. The pain increases with ...\n",
            "    Groundedness Rating: 5. All factual claims are fully supported\n",
            "    Relevance Rating: 5\n",
            "The response directly addresses the question by\n",
            "    Testing Query: Query 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "llama_perf_context_print:        load time =    1484.88 ms\n",
            "llama_perf_context_print: prompt eval time =   52717.86 ms /   690 tokens (   76.40 ms per token,    13.09 tokens per second)\n",
            "llama_perf_context_print:        eval time =   20791.38 ms /   127 runs   (  163.71 ms per token,     6.11 tokens per second)\n",
            "llama_perf_context_print:       total time =   73580.84 ms /   817 tokens\n",
            "Llama.generate: 3 prefix-match hit, remaining 835 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    1484.88 ms\n",
            "llama_perf_context_print: prompt eval time =   62865.18 ms /   835 tokens (   75.29 ms per token,    13.28 tokens per second)\n",
            "llama_perf_context_print:        eval time =    1493.03 ms /     9 runs   (  165.89 ms per token,     6.03 tokens per second)\n",
            "llama_perf_context_print:       total time =   64363.12 ms /   844 tokens\n",
            "Llama.generate: 9 prefix-match hit, remaining 821 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    1484.88 ms\n",
            "llama_perf_context_print: prompt eval time =   62989.47 ms /   821 tokens (   76.72 ms per token,    13.03 tokens per second)\n",
            "llama_perf_context_print:        eval time =     325.90 ms /     2 runs   (  162.95 ms per token,     6.14 tokens per second)\n",
            "llama_perf_context_print:       total time =   63317.34 ms /   823 tokens\n",
            "Llama.generate: 3 prefix-match hit, remaining 629 prompt tokens to eval\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    Response: Alopecia areata is a type of sudden, patchy hair loss that affects people with no obvious skin or systemic disorder. The scalp and beard are most frequently affected, but any hairy area may be involve...\n",
            "    Groundedness Rating: 5. The response accurately identifies alo\n",
            "    Relevance Rating: 5\n",
            "    Testing Query: Query 4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "llama_perf_context_print:        load time =    1484.88 ms\n",
            "llama_perf_context_print: prompt eval time =   47633.02 ms /   629 tokens (   75.73 ms per token,    13.21 tokens per second)\n",
            "llama_perf_context_print:        eval time =   20742.87 ms /   127 runs   (  163.33 ms per token,     6.12 tokens per second)\n",
            "llama_perf_context_print:       total time =   68447.60 ms /   756 tokens\n",
            "Llama.generate: 3 prefix-match hit, remaining 774 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    1484.88 ms\n",
            "llama_perf_context_print: prompt eval time =   59334.79 ms /   774 tokens (   76.66 ms per token,    13.04 tokens per second)\n",
            "llama_perf_context_print:        eval time =    1483.30 ms /     9 runs   (  164.81 ms per token,     6.07 tokens per second)\n",
            "llama_perf_context_print:       total time =   60823.08 ms /   783 tokens\n",
            "Llama.generate: 9 prefix-match hit, remaining 760 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    1484.88 ms\n",
            "llama_perf_context_print: prompt eval time =   56872.68 ms /   760 tokens (   74.83 ms per token,    13.36 tokens per second)\n",
            "llama_perf_context_print:        eval time =     333.78 ms /     2 runs   (  166.89 ms per token,     5.99 tokens per second)\n",
            "llama_perf_context_print:       total time =   57208.37 ms /   762 tokens\n",
            "Llama.generate: 3 prefix-match hit, remaining 706 prompt tokens to eval\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    Response: Based on the context provided, the recommended treatments for a person with a brain injury include physical and occupational therapy, skill-building activities, counseling to meet social and emotional...\n",
            "    Groundedness Rating: 5.\n",
            "All factual claims are fully\n",
            "    Relevance Rating: 5\n",
            "    Testing Query: Query 5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "llama_perf_context_print:        load time =    1484.88 ms\n",
            "llama_perf_context_print: prompt eval time =   53934.64 ms /   706 tokens (   76.39 ms per token,    13.09 tokens per second)\n",
            "llama_perf_context_print:        eval time =   20889.15 ms /   127 runs   (  164.48 ms per token,     6.08 tokens per second)\n",
            "llama_perf_context_print:       total time =   74895.19 ms /   833 tokens\n",
            "Llama.generate: 3 prefix-match hit, remaining 851 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    1484.88 ms\n",
            "llama_perf_context_print: prompt eval time =   64223.48 ms /   851 tokens (   75.47 ms per token,    13.25 tokens per second)\n",
            "llama_perf_context_print:        eval time =    1490.83 ms /     9 runs   (  165.65 ms per token,     6.04 tokens per second)\n",
            "llama_perf_context_print:       total time =   65719.29 ms /   860 tokens\n",
            "Llama.generate: 9 prefix-match hit, remaining 837 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    1484.88 ms\n",
            "llama_perf_context_print: prompt eval time =   64135.25 ms /   837 tokens (   76.63 ms per token,    13.05 tokens per second)\n",
            "llama_perf_context_print:        eval time =     336.53 ms /     2 runs   (  168.26 ms per token,     5.94 tokens per second)\n",
            "llama_perf_context_print:       total time =   64473.86 ms /   839 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    Response: Based on the context provided, a femoral shaft fracture is a serious injury that typically requires immediate medical attention. The usual treatment is open reduction and internal fixation (ORIF) foll...\n",
            "    Groundedness Rating: 5\n",
            "All factual claims are fully supported\n",
            "    Relevance Rating: 5\n",
            "\n",
            "--- Combination 5: {'chunk_size': 750, 'chunk_overlap': 150, 'retriever_k': 3, 'llm_max_tokens': 128, 'llm_temperature': 0.1} ---\n",
            "  Created 23993 chunks.\n",
            "  Embedded 23993 chunks.\n",
            "  Retriever created with k=3\n",
            "    Testing Query: Query 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: 3 prefix-match hit, remaining 662 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    1484.88 ms\n",
            "llama_perf_context_print: prompt eval time =   51437.01 ms /   662 tokens (   77.70 ms per token,    12.87 tokens per second)\n",
            "llama_perf_context_print:        eval time =   20773.23 ms /   127 runs   (  163.57 ms per token,     6.11 tokens per second)\n",
            "llama_perf_context_print:       total time =   72280.84 ms /   789 tokens\n",
            "Llama.generate: 3 prefix-match hit, remaining 807 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    1484.88 ms\n",
            "llama_perf_context_print: prompt eval time =   61081.76 ms /   807 tokens (   75.69 ms per token,    13.21 tokens per second)\n",
            "llama_perf_context_print:        eval time =    1461.43 ms /     9 runs   (  162.38 ms per token,     6.16 tokens per second)\n",
            "llama_perf_context_print:       total time =   62548.11 ms /   816 tokens\n",
            "Llama.generate: 9 prefix-match hit, remaining 793 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    1484.88 ms\n",
            "llama_perf_context_print: prompt eval time =   61055.97 ms /   793 tokens (   76.99 ms per token,    12.99 tokens per second)\n",
            "llama_perf_context_print:        eval time =     329.73 ms /     2 runs   (  164.87 ms per token,     6.07 tokens per second)\n",
            "llama_perf_context_print:       total time =   61387.64 ms /   795 tokens\n",
            "Llama.generate: 3 prefix-match hit, remaining 705 prompt tokens to eval\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    Response: The protocol for managing sepsis in a critical care unit includes aggressive fluid resuscitation, administration of antibiotics, surgical excision or drainage of infected or necrotic tissues, supporti...\n",
            "    Groundedness Rating: 5. The response accurately describes the protocol for\n",
            "    Relevance Rating: 5\n",
            "    Testing Query: Query 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "llama_perf_context_print:        load time =    1484.88 ms\n",
            "llama_perf_context_print: prompt eval time =   53044.77 ms /   705 tokens (   75.24 ms per token,    13.29 tokens per second)\n",
            "llama_perf_context_print:        eval time =   20793.85 ms /   127 runs   (  163.73 ms per token,     6.11 tokens per second)\n",
            "llama_perf_context_print:       total time =   73909.46 ms /   832 tokens\n",
            "Llama.generate: 3 prefix-match hit, remaining 848 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    1484.88 ms\n",
            "llama_perf_context_print: prompt eval time =   65034.48 ms /   848 tokens (   76.69 ms per token,    13.04 tokens per second)\n",
            "llama_perf_context_print:        eval time =    1481.33 ms /     9 runs   (  164.59 ms per token,     6.08 tokens per second)\n",
            "llama_perf_context_print:       total time =   66520.85 ms /   857 tokens\n",
            "Llama.generate: 9 prefix-match hit, remaining 834 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    1484.88 ms\n",
            "llama_perf_context_print: prompt eval time =   63180.40 ms /   834 tokens (   75.76 ms per token,    13.20 tokens per second)\n",
            "llama_perf_context_print:        eval time =     343.14 ms /     2 runs   (  171.57 ms per token,     5.83 tokens per second)\n",
            "llama_perf_context_print:       total time =   63525.44 ms /   836 tokens\n",
            "Llama.generate: 3 prefix-match hit, remaining 677 prompt tokens to eval\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    Response: The common symptoms for appendicitis include epigastric or periumbilical pain followed by brief nausea, vomiting, and anorexia, which later shifts to the right lower quadrant. The pain increases with ...\n",
            "    Groundedness Rating: 5\n",
            "The response is fully supported by the\n",
            "    Relevance Rating: 5\n",
            "    Testing Query: Query 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "llama_perf_context_print:        load time =    1484.88 ms\n",
            "llama_perf_context_print: prompt eval time =   51073.18 ms /   677 tokens (   75.44 ms per token,    13.26 tokens per second)\n",
            "llama_perf_context_print:        eval time =   21177.29 ms /   127 runs   (  166.75 ms per token,     6.00 tokens per second)\n",
            "llama_perf_context_print:       total time =   72323.47 ms /   804 tokens\n",
            "Llama.generate: 3 prefix-match hit, remaining 822 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    1484.88 ms\n",
            "llama_perf_context_print: prompt eval time =   61419.09 ms /   822 tokens (   74.72 ms per token,    13.38 tokens per second)\n",
            "llama_perf_context_print:        eval time =    1476.97 ms /     9 runs   (  164.11 ms per token,     6.09 tokens per second)\n",
            "llama_perf_context_print:       total time =   62901.06 ms /   831 tokens\n",
            "Llama.generate: 9 prefix-match hit, remaining 808 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    1484.88 ms\n",
            "llama_perf_context_print: prompt eval time =   61496.16 ms /   808 tokens (   76.11 ms per token,    13.14 tokens per second)\n",
            "llama_perf_context_print:        eval time =     335.51 ms /     2 runs   (  167.76 ms per token,     5.96 tokens per second)\n",
            "llama_perf_context_print:       total time =   61833.65 ms /   810 tokens\n",
            "Llama.generate: 3 prefix-match hit, remaining 611 prompt tokens to eval\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    Response: Based on the context provided, the possible causes for sudden patchy hair loss could be alopecia areata. Effective treatments for alopecia areata include topical, intralesional, or systemic corticoste...\n",
            "    Groundedness Rating: 5. The response accurately identifies alo\n",
            "    Relevance Rating: 5\n",
            "    Testing Query: Query 4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "llama_perf_context_print:        load time =    1484.88 ms\n",
            "llama_perf_context_print: prompt eval time =   45964.15 ms /   611 tokens (   75.23 ms per token,    13.29 tokens per second)\n",
            "llama_perf_context_print:        eval time =   20810.91 ms /   127 runs   (  163.87 ms per token,     6.10 tokens per second)\n",
            "llama_perf_context_print:       total time =   66846.59 ms /   738 tokens\n",
            "Llama.generate: 3 prefix-match hit, remaining 756 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    1484.88 ms\n",
            "llama_perf_context_print: prompt eval time =   56608.90 ms /   756 tokens (   74.88 ms per token,    13.35 tokens per second)\n",
            "llama_perf_context_print:        eval time =    1536.95 ms /     9 runs   (  170.77 ms per token,     5.86 tokens per second)\n",
            "llama_perf_context_print:       total time =   58151.14 ms /   765 tokens\n",
            "Llama.generate: 9 prefix-match hit, remaining 742 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    1484.88 ms\n",
            "llama_perf_context_print: prompt eval time =   56967.39 ms /   742 tokens (   76.78 ms per token,    13.02 tokens per second)\n",
            "llama_perf_context_print:        eval time =     333.10 ms /     2 runs   (  166.55 ms per token,     6.00 tokens per second)\n",
            "llama_perf_context_print:       total time =   57302.37 ms /   744 tokens\n",
            "Llama.generate: 3 prefix-match hit, remaining 647 prompt tokens to eval\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    Response: Do not use contractions or jargon.\n",
            "\n",
            "Answer: For a person with a brain injury resulting in neurologic deficits, rehabilitation is necessary. This includes physical, occupational, and speech therapy, sk...\n",
            "    Groundedness Rating: 5\n",
            "\n",
            "The response is fully supported by\n",
            "    Relevance Rating: 5\n",
            "    Testing Query: Query 5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "llama_perf_context_print:        load time =    1484.88 ms\n",
            "llama_perf_context_print: prompt eval time =   49344.69 ms /   647 tokens (   76.27 ms per token,    13.11 tokens per second)\n",
            "llama_perf_context_print:        eval time =   20857.06 ms /   127 runs   (  164.23 ms per token,     6.09 tokens per second)\n",
            "llama_perf_context_print:       total time =   70274.85 ms /   774 tokens\n",
            "Llama.generate: 3 prefix-match hit, remaining 792 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    1484.88 ms\n",
            "llama_perf_context_print: prompt eval time =   60946.54 ms /   792 tokens (   76.95 ms per token,    12.99 tokens per second)\n",
            "llama_perf_context_print:        eval time =    1479.79 ms /     9 runs   (  164.42 ms per token,     6.08 tokens per second)\n",
            "llama_perf_context_print:       total time =   62431.31 ms /   801 tokens\n",
            "Llama.generate: 9 prefix-match hit, remaining 778 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    1484.88 ms\n",
            "llama_perf_context_print: prompt eval time =   58289.49 ms /   778 tokens (   74.92 ms per token,    13.35 tokens per second)\n",
            "llama_perf_context_print:        eval time =    1504.07 ms /     9 runs   (  167.12 ms per token,     5.98 tokens per second)\n",
            "llama_perf_context_print:       total time =   59798.65 ms /   787 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    Response: Do not add personal opinions or assumptions.\n",
            "\n",
            "The person with a fractured leg should receive initial treatment for any life-threatening injuries, such as hemorrhagic shock. For the fracture itself, th...\n",
            "    Groundedness Rating: 5\n",
            "The response is fully supported by the\n",
            "    Relevance Rating: 5\n",
            "The response directly addresses the question by\n"
          ]
        }
      ],
      "source": [
        "results = {}\n",
        "evaluation_results = {}\n",
        "\n",
        "print(\"\\n--- Fine-tuning RAG Parameters ---\")\n",
        "for i, params in enumerate(param_combinations):\n",
        "    print(f\"\\n--- Combination {i+1}: {params} ---\")\n",
        "\n",
        "    # Chunking (assumes get_data_chunks is defined as in previous code)\n",
        "    current_chunks = get_data_chunks(\n",
        "        documents,\n",
        "        chunk_size=params[\"chunk_size\"],\n",
        "        chunk_overlap=params[\"chunk_overlap\"],\n",
        "        split_method=\"recursive\",\n",
        "        separators=[\"\\n\\n\", \"\\n\", \". \", \" \", \"\"],\n",
        "        min_chunk_size=50,\n",
        "        add_metadata=True\n",
        "    )\n",
        "    print(f\"  Created {len(current_chunks)} chunks.\")\n",
        "\n",
        "    # Embedding\n",
        "    current_embedded_chunks = []\n",
        "    batch_size = 50  # Safe for M4\n",
        "    for j in range(0, len(current_chunks), batch_size):\n",
        "        chunk_batch = current_chunks[j:j+batch_size]\n",
        "        try:\n",
        "            embeddings = embedding_function.embed_documents([chunk.page_content for chunk in chunk_batch])\n",
        "            for chunk, embedding in zip(chunk_batch, embeddings):\n",
        "                current_embedded_chunks.append((chunk, embedding))\n",
        "        except Exception as e:\n",
        "            print(f\"  Error embedding batch {j}: {e}\")\n",
        "    print(f\"  Embedded {len(current_embedded_chunks)} chunks.\")\n",
        "\n",
        "    # Vector Database\n",
        "    persist_directory = f'medical_db_combo_{i+1}'\n",
        "    if os.path.exists(persist_directory):\n",
        "        shutil.rmtree(persist_directory, ignore_errors=True)\n",
        "    os.makedirs(persist_directory, exist_ok=True)\n",
        "\n",
        "    if current_embedded_chunks:\n",
        "        try:\n",
        "            current_vector_db = Chroma.from_documents(\n",
        "                documents=[chunk for chunk, embedding in current_embedded_chunks],\n",
        "                embedding=embedding_function,\n",
        "                persist_directory=persist_directory\n",
        "            )\n",
        "            current_retriever = current_vector_db.as_retriever(\n",
        "                search_type=\"similarity\",\n",
        "                search_kwargs={\"k\": params[\"retriever_k\"]}\n",
        "            )\n",
        "            print(f\"  Retriever created with k={params['retriever_k']}\")\n",
        "\n",
        "            # Query Execution and Evaluation\n",
        "            results[f\"Combination {i+1}\"] = {}\n",
        "            evaluation_results[f\"Combination {i+1}\"] = {}\n",
        "            for query_name, query_text in queries_to_test.items():\n",
        "                print(f\"    Testing Query: {query_name}\")\n",
        "                groundedness_rating, relevance_rating, response_text, context = generate_ground_relevance_response(\n",
        "                    query_text,\n",
        "                    current_retriever\n",
        "                )\n",
        "                results[f\"Combination {i+1}\"][query_name] = response_text\n",
        "                evaluation_results[f\"Combination {i+1}\"][query_name] = {\n",
        "                    \"groundedness_rating\": groundedness_rating,\n",
        "                    \"relevance_rating\": relevance_rating,\n",
        "                    \"context\": context[:200] + \"...\" if context else \"No context\"\n",
        "                }\n",
        "                print(f\"    Response: {response_text[:200]}...\")\n",
        "                print(f\"    Groundedness Rating: {groundedness_rating}\")\n",
        "                print(f\"    Relevance Rating: {relevance_rating}\")\n",
        "        except Exception as e:\n",
        "            print(f\"  Error creating vector DB or retriever: {e}\")\n",
        "    else:\n",
        "        print(\"  No embedded chunks for vector DB.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Response Quality: RAG-based answers are highly accurate, context-specific, and consistently grounded in the provided medical manual (e.g., Merck Manual).\n",
        "\n",
        "Groundedness and Relevance:\n",
        "\n",
        "Answers are directly supported by retrieved context, minimizing hallucination and ensuring factual correctness.\n",
        "\n",
        "The system can handle complex, multi-part queries with detailed, stepwise protocols and explanations.\n",
        "\n",
        "Transparency: The RAG approach enables traceability, as each answer is based on retrieved, authoritative content. This is critical for clinical decision support and regulatory compliance.\n",
        "\n",
        "Consistency: Responses are uniform in style and depth, and ambiguity is minimized. The system can explicitly state when the context is insufficient to answer a question.\n",
        "\n",
        "Limitations:\n",
        "\n",
        "The quality of the answer depends on the quality and coverage of the underlying knowledge base. If the manual lacks information on a rare condition, the answer may be incomplete.\n",
        "\n",
        "Retrieval and generation can be slower than direct LLM responses, especially for large document sets."
      ],
      "metadata": {
        "id": "723V2ovdMGF5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JPgmp_FvqXke",
        "outputId": "7f2615ec-2949-4c25-d8ec-515aed44cf57"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "--- Comparison of Results ---\n",
            "\n",
            "### Query 1: What is the protocol for managing sepsis in a critical care unit?\n",
            "\n",
            "#### Combination 1 (Chunk Size: 500, Overlap: 100, Retriever k: 3, LLM Tokens: 128, LLM Temp: 0)\n",
            "Response: The protocol for managing sepsis in a critical care unit includes controlling hemorrhage, checking and providing respiratory assistance if necessary, keeping the patient warm, avoiding anything by mouth, draining abscesses, and surgically excising necrotic tissues. Septic foci must be eliminated to prevent further deterioration. Normalization of blood glucose also improves outcome.\n",
            "Groundedness Rating: 5. The response is fully supported by the\n",
            "Relevance Rating: 5\n",
            "Context Preview: 16 - Critical Care Medicine\n",
            "Chapter 222. Approach to the Critically Ill Patient\n",
            "Introduction\n",
            "Critical care medicine specializes in caring for the most seriously ill patients. These patients are best\n",
            "t...\n",
            "--------------------------------------------------\n",
            "\n",
            "#### Combination 2 (Chunk Size: 750, Overlap: 150, Retriever k: 5, LLM Tokens: 200, LLM Temp: 0.1)\n",
            "Response: The protocol for managing sepsis in a critical care unit includes aggressive fluid resuscitation, antibiotics, surgical excision of infected or necrotic tissues and drainage of pus, supportive care, and sometimes intensive control of blood glucose and administration of corticosteroids and activated protein C. The severity of sepsis ranges from sepsis, which is infection accompanied by an acute inflammatory reaction with systemic manifestations, to severe sepsis, which is sepsis accompanied by signs of failure of at least one organ, and septic shock, which\n",
            "Groundedness Rating: 5. The response accurately describes the protocol for\n",
            "Relevance Rating: 5\n",
            "Context Preview: 16 - Critical Care Medicine\n",
            "Chapter 222. Approach to the Critically Ill Patient\n",
            "Introduction\n",
            "Critical care medicine specializes in caring for the most seriously ill patients. These patients are best\n",
            "t...\n",
            "--------------------------------------------------\n",
            "\n",
            "#### Combination 3 (Chunk Size: 1000, Overlap: 200, Retriever k: 3, LLM Tokens: 128, LLM Temp: 0)\n",
            "Response: Based on the provided context, the management of sepsis in a critical care unit involves the following steps:\n",
            "1. First aid: Keep the patient warm, control hemorrhage, check the airway and ventilation, and provide respiratory assistance if necessary.\n",
            "2. Supplemental oxygen by face mask.\n",
            "3. Severe or inadequate ventilation requires airway intubation with mechanical ventilation.\n",
            "4. Insert two large IV catheters into separate peripheral veins.\n",
            "5. Provide aggressive fluid resuscitation.\n",
            "6. Administer antibiotics.\n",
            "7\n",
            "Groundedness Rating: 7\n",
            "The response is fully supported by the\n",
            "Relevance Rating: 7\n",
            "The response directly addresses the question by\n",
            "Context Preview: 16 - Critical Care Medicine\n",
            "Chapter 222. Approach to the Critically Ill Patient\n",
            "Introduction\n",
            "Critical care medicine specializes in caring for the most seriously ill patients. These patients are best\n",
            "t...\n",
            "--------------------------------------------------\n",
            "\n",
            "#### Combination 4 (Chunk Size: 500, Overlap: 100, Retriever k: 5, LLM Tokens: 200, LLM Temp: 0.2)\n",
            "Response: Based on the context provided, the protocol for managing sepsis in a critical care unit includes the following steps:\n",
            "1. First aid: Keep the patient warm, control hemorrhage, check and assist airway and ventilation, and turn the patient's head to one side if emesis occurs. Nothing should be given by mouth.\n",
            "2. Management of abscesses and necrotic tissues: Drain abscesses and excise necrotic tissue to eliminate septic foci.\n",
            "3. Normalization of blood glucose: Improves outcome in critically ill patients\n",
            "Groundedness Rating: 5\n",
            "Explanation: The response accurately\n",
            "Relevance Rating: 5\n",
            "Context Preview: 16 - Critical Care Medicine\n",
            "Chapter 222. Approach to the Critically Ill Patient\n",
            "Introduction\n",
            "Critical care medicine specializes in caring for the most seriously ill patients. These patients are best\n",
            "t...\n",
            "--------------------------------------------------\n",
            "\n",
            "#### Combination 5 (Chunk Size: 750, Overlap: 150, Retriever k: 3, LLM Tokens: 128, LLM Temp: 0.1)\n",
            "Response: The protocol for managing sepsis in a critical care unit includes aggressive fluid resuscitation, administration of antibiotics, surgical excision or drainage of infected or necrotic tissues, supportive care, and sometimes intensive control of blood glucose and administration of corticosteroids and activated protein C. The severity of sepsis can vary, and it may be accompanied by signs such as fever, tachycardia, and tachypnea. Sepsis is defined as infection with an acute inflammatory reaction and systemic manifestations, while severe sepsis and\n",
            "Groundedness Rating: 5. The response accurately describes the protocol for\n",
            "Relevance Rating: 5\n",
            "Context Preview: 16 - Critical Care Medicine\n",
            "Chapter 222. Approach to the Critically Ill Patient\n",
            "Introduction\n",
            "Critical care medicine specializes in caring for the most seriously ill patients. These patients are best\n",
            "t...\n",
            "--------------------------------------------------\n",
            "\n",
            "### Query 2: What are the common symptoms for appendicitis, and can it be cured via medicine? If not, what surgical procedure should be followed to treat it?\n",
            "\n",
            "#### Combination 1 (Chunk Size: 500, Overlap: 100, Retriever k: 3, LLM Tokens: 128, LLM Temp: 0)\n",
            "Response: The common symptoms for appendicitis include epigastric or periumbilical pain followed by brief nausea, vomiting, and anorexia, which later shifts to the right lower quadrant. The pain increases with cough and motion. Classic signs include right lower quadrant direct and rebound tenderness at McBurney's point. Appendicitis is caused by obstruction of the appendiceal lumen, typically by lymphoid hyperplasia, but occasionally by other causes. If left untreated, necrosis, gangrene, and perforation can occur. There\n",
            "Groundedness Rating: 5. The response accurately describes the common symptoms\n",
            "Relevance Rating: 5\n",
            "Context Preview: Symptoms and Signs\n",
            "The classic symptoms of acute appendicitis are epigastric or periumbilical pain followed by brief nausea,\n",
            "vomiting, and anorexia; after a few hours, the pain shifts to the right low...\n",
            "--------------------------------------------------\n",
            "\n",
            "#### Combination 2 (Chunk Size: 750, Overlap: 150, Retriever k: 5, LLM Tokens: 200, LLM Temp: 0.1)\n",
            "Response: Do not use I or we.\n",
            "\n",
            "The common symptoms of appendicitis include epigastric or periumbilical pain followed by brief nausea, vomiting, and anorexia, which later shifts to the right lower quadrant. Pain increases with cough and motion. The classic signs are right lower quadrant direct and rebound tenderness. Acute appendicitis is the most common cause of acute abdominal pain requiring surgery in the US, affecting over 5% of the population, most commonly in the teens and 20s. Appendicitis can result from obstruction of the\n",
            "Groundedness Rating: 5\n",
            "All factual claims are fully supported\n",
            "Relevance Rating: 5\n",
            "The response directly addresses the question by\n",
            "Context Preview: Etiology\n",
            "Appendicitis is thought to result from obstruction of the appendiceal lumen, typically by lymphoid\n",
            "hyperplasia, but occasionally by a fecalith, foreign body, or even worms. The obstruction le...\n",
            "--------------------------------------------------\n",
            "\n",
            "#### Combination 3 (Chunk Size: 1000, Overlap: 200, Retriever k: 3, LLM Tokens: 128, LLM Temp: 0)\n",
            "Response: Appendicitis is characterized by symptoms such as epigastric or periumbilical pain followed by brief nausea, vomiting, and anorexia, which later shifts to the right lower quadrant. Pain increases with cough and motion. Classic signs include right lower quadrant direct and rebound tenderness at McBurney's point. If an abscess or inflammatory mass has formed, the procedure may be limited to drainage of the abscess. Appendicitis cannot be cured via medicine, and the standard treatment is surgical removal.\n",
            "Groundedness Rating: 5. All factual claims are fully supported\n",
            "Relevance Rating: 5\n",
            "Context Preview: Etiology\n",
            "Appendicitis is thought to result from obstruction of the appendiceal lumen, typically by lymphoid\n",
            "hyperplasia, but occasionally by a fecalith, foreign body, or even worms. The obstruction le...\n",
            "--------------------------------------------------\n",
            "\n",
            "#### Combination 4 (Chunk Size: 500, Overlap: 100, Retriever k: 5, LLM Tokens: 200, LLM Temp: 0.2)\n",
            "Response: The common symptoms for appendicitis include epigastric or periumbilical pain followed by brief nausea, vomiting, and anorexia, which later shifts to the right lower quadrant. The pain increases with cough and motion. The classic sign is right lower quadrant direct and rebound tenderness located at McBurney's point. Appendicitis is caused by obstruction of the appendiceal lumen, typically by lymphoid hyperplasia, but occasionally by a fecalith, foreign body, or even worms. If untreated, necrosis, gang\n",
            "Groundedness Rating: 5. All factual claims are fully supported\n",
            "Relevance Rating: 5\n",
            "The response directly addresses the question by\n",
            "Context Preview: Symptoms and Signs\n",
            "The classic symptoms of acute appendicitis are epigastric or periumbilical pain followed by brief nausea,\n",
            "vomiting, and anorexia; after a few hours, the pain shifts to the right low...\n",
            "--------------------------------------------------\n",
            "\n",
            "#### Combination 5 (Chunk Size: 750, Overlap: 150, Retriever k: 3, LLM Tokens: 128, LLM Temp: 0.1)\n",
            "Response: The common symptoms for appendicitis include epigastric or periumbilical pain followed by brief nausea, vomiting, and anorexia, which later shifts to the right lower quadrant. The pain increases with cough and motion. The classic signs are right lower quadrant direct and rebound tenderness. Appendicitis is typically treated with surgical removal, as it cannot be cured with medicine. In the US, it is the most common cause of acute abdominal pain requiring surgery, and it can occur at any age, but most commonly in the teens and 20s\n",
            "Groundedness Rating: 5\n",
            "The response is fully supported by the\n",
            "Relevance Rating: 5\n",
            "Context Preview: Etiology\n",
            "Appendicitis is thought to result from obstruction of the appendiceal lumen, typically by lymphoid\n",
            "hyperplasia, but occasionally by a fecalith, foreign body, or even worms. The obstruction le...\n",
            "--------------------------------------------------\n",
            "\n",
            "### Query 3: What are the effective treatments or solutions for addressing sudden patchy hair loss, commonly seen as localized bald spots on the scalp, and what could be the possible causes behind it?\n",
            "\n",
            "#### Combination 1 (Chunk Size: 500, Overlap: 100, Retriever k: 3, LLM Tokens: 128, LLM Temp: 0)\n",
            "Response: Alopecia areata is a type of nonscarring alopecia characterized by sudden, patchy hair loss. The scalp and beard are most commonly affected, but any hairy area can be involved. The cause is not clear, but it is believed to be an autoimmune disorder. Treatment options include topical corticosteroids, topical minoxidil, topical anthralin, topical immunotherapy (diphencyprone or squaric acid dibutylester), or systemic corticosteroids for severe cases. It is important to rule out underlying\n",
            "Groundedness Rating: 5\n",
            "The response accurately identifies alo\n",
            "Relevance Rating: 5\n",
            "Context Preview: been subjected to scientific scrutiny, but patients who are self-conscious about their hair loss may\n",
            "consider them.\n",
            "Hair loss due to other causes: Underlying disorders are treated.\n",
            "Multiple treatment ...\n",
            "--------------------------------------------------\n",
            "\n",
            "#### Combination 2 (Chunk Size: 750, Overlap: 150, Retriever k: 5, LLM Tokens: 200, LLM Temp: 0.1)\n",
            "Response: Androgenetic alopecia is the most common cause of hair loss, but sudden patchy hair loss, also known as alopecia areata, is a different condition. Alopecia areata is an autoimmune disorder affecting genetically susceptible individuals, and it results in sudden, patchy hair loss. The scalp and beard are most frequently affected, but any hairy area may be involved. Treatment options for alopecia areata include topical, intralesional, or systemic corticosteroids, topical minoxidil, topical anthralin, and\n",
            "Groundedness Rating: 5. All factual claims are fully supported\n",
            "Relevance Rating: 5. The response directly addresses the question by\n",
            "Context Preview: for women and is contraindicated in pregnant women because it has teratogenic effects in animals.\n",
            "Hormonal modulators such as oral contraceptives or spironolactone may be useful for female-pattern\n",
            "hai...\n",
            "--------------------------------------------------\n",
            "\n",
            "#### Combination 3 (Chunk Size: 1000, Overlap: 200, Retriever k: 3, LLM Tokens: 128, LLM Temp: 0)\n",
            "Response: Based on the context provided, the possible causes of sudden patchy hair loss could be alopecia areata, tinea capitis, trichotillomania, or scarring alopecia. The effective treatments for alopecia areata include topical, intralesional, or systemic corticosteroids, topical minoxidil, topical anthralin, topical immunotherapy (diphencyprone or squaric acid dibutylester), or psoralen plus ultraviolet A (PUVA). For tinea capitis, treatment involves\n",
            "Groundedness Rating: 5. The response fully supports the factual\n",
            "Relevance Rating: 5\n",
            "The response directly addresses the question by\n",
            "Context Preview: hair loss associated with hyperandrogenemia.\n",
            "Surgical options include follicle transplant, scalp flaps, and alopecia reduction. Few procedures have\n",
            "been subjected to scientific scrutiny, but patients ...\n",
            "--------------------------------------------------\n",
            "\n",
            "#### Combination 4 (Chunk Size: 500, Overlap: 100, Retriever k: 5, LLM Tokens: 200, LLM Temp: 0.2)\n",
            "Response: Alopecia areata is a type of sudden, patchy hair loss that affects people with no obvious skin or systemic disorder. The scalp and beard are most frequently affected, but any hairy area may be involved. The cause of alopecia areata is not fully understood, but it is believed to involve an abnormal immune response that attacks the hair follicles. Treatment options for alopecia areata include topical, intralesional, or systemic corticosteroids, topical minoxidil, topical anthralin, topical immunotherapy (diphen\n",
            "Groundedness Rating: 5. The response accurately identifies alo\n",
            "Relevance Rating: 5\n",
            "Context Preview: been subjected to scientific scrutiny, but patients who are self-conscious about their hair loss may\n",
            "consider them.\n",
            "Hair loss due to other causes: Underlying disorders are treated.\n",
            "Multiple treatment ...\n",
            "--------------------------------------------------\n",
            "\n",
            "#### Combination 5 (Chunk Size: 750, Overlap: 150, Retriever k: 3, LLM Tokens: 128, LLM Temp: 0.1)\n",
            "Response: Based on the context provided, the possible causes for sudden patchy hair loss could be alopecia areata. Effective treatments for alopecia areata include topical, intralesional, or systemic corticosteroids, topical minoxidil, topical anthralin, or topical immunotherapy (diphencyprone or squaric acid dibutyl ester). These treatments aim to stimulate hair regrowth and reduce inflammation in the affected areas. Daily hair counts can also be done to quantify hair loss when the pull test is negative. It\n",
            "Groundedness Rating: 5. The response accurately identifies alo\n",
            "Relevance Rating: 5\n",
            "Context Preview: for women and is contraindicated in pregnant women because it has teratogenic effects in animals.\n",
            "Hormonal modulators such as oral contraceptives or spironolactone may be useful for female-pattern\n",
            "hai...\n",
            "--------------------------------------------------\n",
            "\n",
            "### Query 4: What treatments are recommended for a person who has sustained a physical injury to brain tissue, resulting in temporary or permanent impairment of brain function?\n",
            "\n",
            "#### Combination 1 (Chunk Size: 500, Overlap: 100, Retriever k: 3, LLM Tokens: 128, LLM Temp: 0)\n",
            "Response: Use only the information provided in the context.\n",
            "\n",
            "The Merck Manual suggests a team approach to treating brain injury that includes physical, occupational, and speech therapy, skill-building activities, and counseling to address social and emotional needs. For patients whose coma lasts more than 24 hours and 50% of whom have major persistent neurologic sequelae, a prolonged period of rehabilitation, particularly in cognitive and emotional areas, is often necessary. Physical and occupational therapy can modestly improve functioning but is more often used to make the environment safer and to provide devices that help patients circum\n",
            "Groundedness Rating: 5. The response accurately reflects the context,\n",
            "Relevance Rating: 5. The response directly addresses the question by\n",
            "Context Preview: through a team approach that combines physical, occupational, and speech therapy, skill-building\n",
            "activities, and counseling to meet the patient's social and emotional needs (see also p. 3467). Brain i...\n",
            "--------------------------------------------------\n",
            "\n",
            "#### Combination 2 (Chunk Size: 750, Overlap: 150, Retriever k: 5, LLM Tokens: 200, LLM Temp: 0.1)\n",
            "Response: Do not offer opinions or speculate.\n",
            "\n",
            "Answer: For a person with a brain injury resulting in neurologic deficits, rehabilitation is necessary. This typically involves a team approach combining physical, occupational, and speech therapy, skill-building activities, and counseling to address cognitive and emotional needs. The capacity for recovery from brain injury varies and depends on the individual's age, general health, and the plasticity of the remaining cerebrum. Severe damage often results in permanent deficits. Supportive care is crucial to prevent systemic complications and ensure good nutrition. There is no specific\n",
            "Groundedness Rating: 5. The response accurately reflects the context,\n",
            "Relevance Rating: 5. The response directly addresses the question by\n",
            "Context Preview: For patients whose coma exceeds 24 h, 50% of whom have major persistent neurologic sequelae, a\n",
            "prolonged period of rehabilitation, particularly in cognitive and emotional areas, is often required.\n",
            "Reh...\n",
            "--------------------------------------------------\n",
            "\n",
            "#### Combination 3 (Chunk Size: 1000, Overlap: 200, Retriever k: 3, LLM Tokens: 128, LLM Temp: 0)\n",
            "Response: Early intervention by rehabilitation specialists is crucial for maximal functional recovery. This includes prevention of secondary disabilities, such as pressure ulcers and joint contractures, prevention of pneumonia, and family education. For patients with spinal cord injuries, specific rehabilitation therapy varies depending on the level and extent of the injury. Physical and occupational therapy may modestly improve functioning. For irreversible or progressive disorders, supportive care is recommended, including preventing systemic complications, providing good nutrition, preventing pressure ulcers, and providing physical therapy to prevent limb contractures. There is no specific medical treatment for brain injuries. Dru\n",
            "Groundedness Rating: 5. The response accurately reflects the context,\n",
            "Relevance Rating: 5\n",
            "Context Preview: is common.\n",
            "Early intervention by rehabilitation specialists is indispensable for maximal functional recovery (see also\n",
            "p. 3231). Such intervention includes prevention of secondary disabilities (eg, pr...\n",
            "--------------------------------------------------\n",
            "\n",
            "#### Combination 4 (Chunk Size: 500, Overlap: 100, Retriever k: 5, LLM Tokens: 200, LLM Temp: 0.2)\n",
            "Response: Based on the context provided, the recommended treatments for a person with a brain injury include physical and occupational therapy, skill-building activities, counseling to meet social and emotional needs, and participation in brain injury support groups. There is no specific medical treatment for brain injuries, and drugs that slow the progression of dementia do not appear beneficial. For patients with severe cognitive dysfunction, extensive cognitive therapy is often required and should be prioritized. The need for surgery depends on the specific injury, such as intracranial hematomas which may require urgent surgical evacuation. Prevention measures include CPR for card\n",
            "Groundedness Rating: 5.\n",
            "All factual claims are fully\n",
            "Relevance Rating: 5\n",
            "Context Preview: through a team approach that combines physical, occupational, and speech therapy, skill-building\n",
            "activities, and counseling to meet the patient's social and emotional needs (see also p. 3467). Brain i...\n",
            "--------------------------------------------------\n",
            "\n",
            "#### Combination 5 (Chunk Size: 750, Overlap: 150, Retriever k: 3, LLM Tokens: 128, LLM Temp: 0.1)\n",
            "Response: Do not use contractions or jargon.\n",
            "\n",
            "Answer: For a person with a brain injury resulting in neurologic deficits, rehabilitation is necessary. This includes physical, occupational, and speech therapy, skill-building activities, and counseling to address cognitive, emotional, and social needs. Supportive care is crucial to prevent systemic complications, such as pneumonia, urinary tract infections, and thromboembolic disease, and to ensure good nutrition. For those with a coma lasting over 24 hours, about half will have major persistent neurologic sequ\n",
            "Groundedness Rating: 5\n",
            "\n",
            "The response is fully supported by\n",
            "Relevance Rating: 5\n",
            "Context Preview: For patients whose coma exceeds 24 h, 50% of whom have major persistent neurologic sequelae, a\n",
            "prolonged period of rehabilitation, particularly in cognitive and emotional areas, is often required.\n",
            "Reh...\n",
            "--------------------------------------------------\n",
            "\n",
            "### Query 5: What are the necessary precautions and treatment steps for a person who has fractured their leg during a hiking trip, and what should be considered for their care and recovery?\n",
            "\n",
            "#### Combination 1 (Chunk Size: 500, Overlap: 100, Retriever k: 3, LLM Tokens: 128, LLM Temp: 0)\n",
            "Response: Based on the context provided, a femoral shaft fracture is a serious injury that requires immediate medical attention. The usual treatment is open reduction and internal fixation (ORIF) and early mobilization. The person should be splinted as soon as possible to prevent further damage and loss of blood. Once stabilized, they should begin rehabilitation with stretching and strengthening exercises. Rest, ice, and compression with the use of a thigh sleeve should also be implemented. The person may require crutches for initial mobility and should avoid putting weight on the injured leg for several days to ensure proper healing. Wound care is also\n",
            "Groundedness Rating: 5. The response accurately reflects the context provided\n",
            "Relevance Rating: 5\n",
            "Context Preview: are usually diagnostic. Treatment is usually ORIF and early mobilization.\n",
            "Femoral shaft fractures: The usual injury mechanism is severe direct force or an axial load to the flexed\n",
            "knee. Fracture due t...\n",
            "--------------------------------------------------\n",
            "\n",
            "#### Combination 2 (Chunk Size: 750, Overlap: 150, Retriever k: 5, LLM Tokens: 200, LLM Temp: 0.1)\n",
            "Response: Based on the context provided, the person has sustained a fracture, likely in their leg. The Merck Manual suggests initial treatment includes rest, ice, compression, and elevation (RICE). Depending on the severity of the injury, splinting, definitive treatment (such as reduction), and immobilization may also be necessary. For life-threatening injuries, treatment focuses on addressing any hemorrhagic shock or damage to arteries or nerves. Complications, such as blood loss, fat embolism, and deep vein thrombosis (DVT), should be prevented\n",
            "Groundedness Rating: 5\n",
            "All factual claims are fully supported\n",
            "Relevance Rating: 5\n",
            "Context Preview: weakness are present.\n",
            "Treatment\n",
            "• Rest, ice, and compression\n",
            "• Stretching, then strengthening exercises\n",
            "Ice and compression with use of a thigh sleeve should begin as soon as possible. NSAIDs and anal...\n",
            "--------------------------------------------------\n",
            "\n",
            "#### Combination 3 (Chunk Size: 1000, Overlap: 200, Retriever k: 3, LLM Tokens: 128, LLM Temp: 0)\n",
            "Response: The person with a fractured leg should be assessed for potential life-threatening complications such as rapid blood loss and fat embolism. If the fracture is open, keeping the limb off the ground and applying meticulous wound care are essential to prevent infection. The wound should be kept clean and dry, and nonadherent and impermeable dressings should be used. Antibiotic ointment should be applied daily until the wound closure device is removed. For higher risk wounds or wounds in unreliable patients, early physician examination is recommended. Treatment for life- or limb-th\n",
            "Groundedness Rating: 5. The response accurately references the context,\n",
            "Relevance Rating: 5\n",
            "Context Preview: Chapter 323. Fractures, Dislocations, and Sprains\n",
            "Introduction\n",
            "Fractures, joint dislocations, ligament sprains, muscle strains, and tendon injuries are common injuries\n",
            "that vary greatly in severity an...\n",
            "--------------------------------------------------\n",
            "\n",
            "#### Combination 4 (Chunk Size: 500, Overlap: 100, Retriever k: 5, LLM Tokens: 200, LLM Temp: 0.2)\n",
            "Response: Based on the context provided, a femoral shaft fracture is a serious injury that typically requires immediate medical attention. The usual treatment is open reduction and internal fixation (ORIF) followed by early mobilization. In the initial stages, the person should be splinted to prevent further damage and loss of blood. Once stabilized, they should be transported to a medical facility for further treatment. During their recovery, they may require crutches or other assistive devices, and meticulous wound care is necessary if there is an associated laceration. Additionally, precautions to prevent deep venous thrombosis may\n",
            "Groundedness Rating: 5\n",
            "All factual claims are fully supported\n",
            "Relevance Rating: 5\n",
            "Context Preview: are usually diagnostic. Treatment is usually ORIF and early mobilization.\n",
            "Femoral shaft fractures: The usual injury mechanism is severe direct force or an axial load to the flexed\n",
            "knee. Fracture due t...\n",
            "--------------------------------------------------\n",
            "\n",
            "#### Combination 5 (Chunk Size: 750, Overlap: 150, Retriever k: 3, LLM Tokens: 128, LLM Temp: 0.1)\n",
            "Response: Do not add personal opinions or assumptions.\n",
            "\n",
            "The person with a fractured leg should receive initial treatment for any life-threatening injuries, such as hemorrhagic shock. For the fracture itself, the following steps should be taken:\n",
            "\n",
            "1. Splinting: Apply a splint to help stabilize the fracture and prevent further injury.\n",
            "2. Definitive treatment: Depending on the type and severity of the fracture, definitive treatment may be necessary, such as reduction (manipulation to realign the bone).\n",
            "3. Rest, ice, compression, and\n",
            "Groundedness Rating: 5\n",
            "The response is fully supported by the\n",
            "Relevance Rating: 5\n",
            "The response directly addresses the question by\n",
            "Context Preview: weakness are present.\n",
            "Treatment\n",
            "• Rest, ice, and compression\n",
            "• Stretching, then strengthening exercises\n",
            "Ice and compression with use of a thigh sleeve should begin as soon as possible. NSAIDs and anal...\n",
            "--------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "# --- Compare Results ---\n",
        "print(\"\\n\\n--- Comparison of Results ---\")\n",
        "for query_name, query_text in queries_to_test.items():\n",
        "    print(f\"\\n### {query_name}: {query_text}\")\n",
        "    for combo_name, query_results in results.items():\n",
        "        response_text = query_results.get(query_name, \"Response not found\")\n",
        "        eval_data = evaluation_results.get(combo_name, {}).get(query_name, {})\n",
        "        print(f\"\\n#### {combo_name} (Chunk Size: {param_combinations[int(combo_name.split(' ')[1])-1]['chunk_size']}, \"\n",
        "              f\"Overlap: {param_combinations[int(combo_name.split(' ')[1])-1]['chunk_overlap']}, \"\n",
        "              f\"Retriever k: {param_combinations[int(combo_name.split(' ')[1])-1]['retriever_k']}, \"\n",
        "              f\"LLM Tokens: {param_combinations[int(combo_name.split(' ')[1])-1]['llm_max_tokens']}, \"\n",
        "              f\"LLM Temp: {param_combinations[int(combo_name.split(' ')[1])-1]['llm_temperature']})\")\n",
        "        print(f\"Response: {response_text}\")\n",
        "        print(f\"Groundedness Rating: {eval_data.get('groundedness_rating', 'N/A')}\")\n",
        "        print(f\"Relevance Rating: {eval_data.get('relevance_rating', 'N/A')}\")\n",
        "        print(f\"Context Preview: {eval_data.get('context', 'N/A')}\")\n",
        "        print(\"-\" * 50)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rtYPOGhFqXkf",
        "outputId": "8147a59d-677e-43da-cb34-c5df81b52ef4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Evaluation Results Summary ---\n",
            "                                                            Groundedness  \\\n",
            "Combination 1 Query 1          5. The response is fully supported by the   \n",
            "              Query 2  5. The response accurately describes the commo...   \n",
            "              Query 3          5\\nThe response accurately identifies alo   \n",
            "              Query 4   5. The response accurately reflects the context,   \n",
            "              Query 5  5. The response accurately reflects the contex...   \n",
            "Combination 2 Query 1  5. The response accurately describes the proto...   \n",
            "              Query 2          5\\nAll factual claims are fully supported   \n",
            "              Query 3          5. All factual claims are fully supported   \n",
            "              Query 4   5. The response accurately reflects the context,   \n",
            "              Query 5          5\\nAll factual claims are fully supported   \n",
            "Combination 3 Query 1          7\\nThe response is fully supported by the   \n",
            "              Query 2          5. All factual claims are fully supported   \n",
            "              Query 3         5. The response fully supports the factual   \n",
            "              Query 4   5. The response accurately reflects the context,   \n",
            "              Query 5  5. The response accurately references the cont...   \n",
            "Combination 4 Query 1            5\\nExplanation: The response accurately   \n",
            "              Query 2          5. All factual claims are fully supported   \n",
            "              Query 3          5. The response accurately identifies alo   \n",
            "              Query 4                   5.\\nAll factual claims are fully   \n",
            "              Query 5          5\\nAll factual claims are fully supported   \n",
            "Combination 5 Query 1  5. The response accurately describes the proto...   \n",
            "              Query 2          5\\nThe response is fully supported by the   \n",
            "              Query 3          5. The response accurately identifies alo   \n",
            "              Query 4            5\\n\\nThe response is fully supported by   \n",
            "              Query 5          5\\nThe response is fully supported by the   \n",
            "\n",
            "                                                               Relevance  \n",
            "Combination 1 Query 1                                                  5  \n",
            "              Query 2                                                  5  \n",
            "              Query 3                                                  5  \n",
            "              Query 4  5. The response directly addresses the questio...  \n",
            "              Query 5                                                  5  \n",
            "Combination 2 Query 1                                                  5  \n",
            "              Query 2  5\\nThe response directly addresses the questio...  \n",
            "              Query 3  5. The response directly addresses the questio...  \n",
            "              Query 4  5. The response directly addresses the questio...  \n",
            "              Query 5                                                  5  \n",
            "Combination 3 Query 1  7\\nThe response directly addresses the questio...  \n",
            "              Query 2                                                  5  \n",
            "              Query 3  5\\nThe response directly addresses the questio...  \n",
            "              Query 4                                                  5  \n",
            "              Query 5                                                  5  \n",
            "Combination 4 Query 1                                                  5  \n",
            "              Query 2  5\\nThe response directly addresses the questio...  \n",
            "              Query 3                                                  5  \n",
            "              Query 4                                                  5  \n",
            "              Query 5                                                  5  \n",
            "Combination 5 Query 1                                                  5  \n",
            "              Query 2                                                  5  \n",
            "              Query 3                                                  5  \n",
            "              Query 4                                                  5  \n",
            "              Query 5  5\\nThe response directly addresses the questio...  \n"
          ]
        }
      ],
      "source": [
        "# --- Evaluation Summary ---\n",
        "print(\"\\n--- Evaluation Results Summary ---\")\n",
        "eval_summary = {}\n",
        "for combo_name in evaluation_results:\n",
        "    eval_summary[combo_name] = {}\n",
        "    for query_name in queries_to_test:\n",
        "        eval_data = evaluation_results[combo_name].get(query_name, {})\n",
        "        eval_summary[combo_name][query_name] = {\n",
        "            \"Groundedness\": eval_data.get(\"groundedness_rating\", \"N/A\"),\n",
        "            \"Relevance\": eval_data.get(\"relevance_rating\", \"N/A\")\n",
        "        }\n",
        "eval_df = pd.DataFrame.from_dict({(c, q): eval_summary[c][q] for c in eval_summary for q in eval_summary[c]}, orient='index')\n",
        "print(eval_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Actionable Insights and Recommendations**\n",
        "\n",
        "**Key Business Insights**\n",
        "\n",
        "1.Implementing a Retrieval-Augmented Generation (RAG) system using trusted medical manuals (e.g., Merck Manual) enables healthcare professionals to access accurate, up-to-date information rapidly, reducing time spent searching for answers and minimizing information overload.\n",
        "\n",
        "2.Automated, context-aware responses to common clinical questions (diagnosis, treatment, drug information) streamline decision-making, especially in high-pressure environments like critical care.\n",
        "\n",
        "3.Centralizing medical knowledge and protocols through AI ensures consistent application of best practices across the organization, reducing variability in care and supporting evidence-based medicine.\n",
        "\n",
        "4.The system’s ability to provide grounded, relevant, and context-specific answers supports safer, more reliable patient management.\n",
        "\n",
        "5.The RAG-based solution is scalable: as new medical knowledge emerges, the system can be updated without retraining the core AI, ensuring ongoing relevance and compliance.\n",
        "\n",
        "6.By automating routine queries and triage, clinical staff can focus on complex cases, improving workforce productivity and reducing burnout.\n",
        "\n",
        "7.Usage analytics from the AI system can identify knowledge gaps, frequently asked questions, and areas where additional staff training or protocol updates are needed.\n",
        "\n",
        "8.Continuous evaluation of AI responses (groundedness and relevance ratings) provides a feedback loop for system improvement and regulatory compliance.\n",
        "\n",
        "**Recommendations**\n",
        "\n",
        "1.Deploy the AI assistant at key points of care (e.g., nurse stations,\n",
        "emergency rooms, telemedicine platforms) to support real-time clinical decision-making.\n",
        "\n",
        "2.Ensure seamless interoperability with existing electronic health record (EHR) systems for context-aware recommendations.\n",
        "\n",
        "3.Start with high-frequency, high-risk clinical scenarios (e.g., sepsis management, acute abdominal pain, trauma protocols) to maximize immediate value and demonstrate ROI.\n",
        "\n",
        "4.Expand coverage to specialty knowledge and rare conditions as the system matures.\n",
        "\n",
        "5.Provide targeted training for clinicians to build trust in AI recommendations and clarify the system’s role as a decision-support tool, not a replacement for clinical judgment.\n",
        "\n",
        "6.Establish clear escalation protocols for ambiguous or unsupported queries.\n",
        "\n",
        "7.Regularly review system performance using groundedness and relevance metrics to ensure accuracy and clinical safety.\n",
        "\n",
        "8.Use analytics to refine knowledge bases, update protocols, and identify opportunities for further automation.\n",
        "\n",
        "9.Ensure all patient data and medical content are handled in compliance with healthcare regulations (e.g., HIPAA).\n",
        "\n",
        "10.Maintain transparency in AI decision-making to support auditability and regulatory review.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "tGmIaQH6FDW7"
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "3CNz35ia6Bz3",
        "CkRbhMJH6Bz3",
        "CARPKFwm6Bz4",
        "by9EvAnkSpZf",
        "lnwETBOE6Bz5",
        "TtZWqj0wFTS1",
        "Uq1lhM4WFTS2",
        "EzzkvIXvFTS4",
        "K8YgK91SFjVY",
        "J6yxICeVFjVc",
        "oflaoOGiFjVd",
        "WUUqY4FbFjVe",
        "5laPFTHrFjVf",
        "g5myZ5dOOefc",
        "9Jg3r_LWOeff",
        "iYpyw4HjOeff",
        "dRp92JQZOeff",
        "AA45zwyUOefg",
        "TYXxiSuBOefg",
        "t_O1PGdNO2M9",
        "uTpWESc53dL9",
        "ffj0ca3eZT4u",
        "f9weTDzMxRRS",
        "7-wNNalNxPKT",
        "LECMxTH-zB-R",
        "BvHVejcWz0Bl",
        "qiKCOv4X0d7B",
        "uEa5sKc41T1z",
        "vw8qcwq66B0C",
        "TkIteX4m6mny",
        "ffP1SRYbPQHN",
        "JjajBEj06B0E",
        "QDw8zXuq6B0F",
        "TggYyQPL6B0G",
        "1TgxdI-_6B0G",
        "FlHXYCkm6B0H",
        "K7TYrqycEITB",
        "Y7QICRU-njdj"
      ],
      "gpuType": "A100",
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernel_info": {
      "name": "python310-sdkv2"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.3"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      },
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0390af2342204727b89674f8073b6a7b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1e3007a584504b23a3be5e32fc630458",
              "IPY_MODEL_cb1de09892634e419c54b3ef21653144",
              "IPY_MODEL_f66d84a88635483b8b9d389df158caca"
            ],
            "layout": "IPY_MODEL_6a5df697af3a449bb365510218d82550"
          }
        },
        "1e3007a584504b23a3be5e32fc630458": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_205f9fe8522941e88ba954024a6a18c8",
            "placeholder": "​",
            "style": "IPY_MODEL_597325b6091d4416992eb70bdbe4c1a5",
            "value": "mistral-7b-instruct-v0.2.Q6_K.gguf: 100%"
          }
        },
        "cb1de09892634e419c54b3ef21653144": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_db773b60d2ac4ccd8b29af7960124e8b",
            "max": 5942065440,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_22093be185744babac4caa06a0312516",
            "value": 5942065440
          }
        },
        "f66d84a88635483b8b9d389df158caca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dd7d49b2f6e24cf4932c4c99b26a6cad",
            "placeholder": "​",
            "style": "IPY_MODEL_9b92a2ad19994e16b3f3046a10564870",
            "value": " 5.94G/5.94G [00:23&lt;00:00, 247MB/s]"
          }
        },
        "6a5df697af3a449bb365510218d82550": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "205f9fe8522941e88ba954024a6a18c8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "597325b6091d4416992eb70bdbe4c1a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "db773b60d2ac4ccd8b29af7960124e8b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "22093be185744babac4caa06a0312516": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "dd7d49b2f6e24cf4932c4c99b26a6cad": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9b92a2ad19994e16b3f3046a10564870": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "942653e57d0147c1820313e10c2d4195": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_72ef9cb5e9af48148a1f6d89c3d4349d",
              "IPY_MODEL_43122ff0685d4feaae391dfff7d7c3f4",
              "IPY_MODEL_2c509a9e97f34a679a494270601b59dc"
            ],
            "layout": "IPY_MODEL_431df39a2cfb4ce3a9c40cf839b36ef9"
          }
        },
        "72ef9cb5e9af48148a1f6d89c3d4349d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_33a227dbb5794b6180fe6d7fc49bf46f",
            "placeholder": "​",
            "style": "IPY_MODEL_d753cb6b566a492e9cfe766ce1cb6214",
            "value": "modules.json: 100%"
          }
        },
        "43122ff0685d4feaae391dfff7d7c3f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_902c6298bc9547bbbea4e15a0faaf007",
            "max": 349,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3ce5fa657d3e4116a3b0afcd61ad5977",
            "value": 349
          }
        },
        "2c509a9e97f34a679a494270601b59dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a9e7b8f4dfe542fb91fd7cadf996c458",
            "placeholder": "​",
            "style": "IPY_MODEL_7353ed65ab31404f938b81ab59913349",
            "value": " 349/349 [00:00&lt;00:00, 41.9kB/s]"
          }
        },
        "431df39a2cfb4ce3a9c40cf839b36ef9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "33a227dbb5794b6180fe6d7fc49bf46f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d753cb6b566a492e9cfe766ce1cb6214": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "902c6298bc9547bbbea4e15a0faaf007": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3ce5fa657d3e4116a3b0afcd61ad5977": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a9e7b8f4dfe542fb91fd7cadf996c458": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7353ed65ab31404f938b81ab59913349": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "82910528cb7640b986101f77dd2f0ef9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_70aa7a3a618e43109bfefe13d22780d6",
              "IPY_MODEL_a045bb70be7a4d669081dafb8559897b",
              "IPY_MODEL_d9485c21963d4a7fa04aad4707e65c6a"
            ],
            "layout": "IPY_MODEL_b9a6ff8d65ef434bac89045afd60911b"
          }
        },
        "70aa7a3a618e43109bfefe13d22780d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1872a02d29a54656a14205959ee6cfb9",
            "placeholder": "​",
            "style": "IPY_MODEL_7695c4739a1144809ad0c82ea12bfad3",
            "value": "config_sentence_transformers.json: 100%"
          }
        },
        "a045bb70be7a4d669081dafb8559897b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f3b44230fcdb4fc996bd316cc4bdd8a3",
            "max": 116,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4ca3f5689b1a473f95041452dd3e8fe4",
            "value": 116
          }
        },
        "d9485c21963d4a7fa04aad4707e65c6a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d8c57ffc6ba5463aabd16046fcbe41a7",
            "placeholder": "​",
            "style": "IPY_MODEL_25d60a2e2ec24ab1b3737551420ac608",
            "value": " 116/116 [00:00&lt;00:00, 13.6kB/s]"
          }
        },
        "b9a6ff8d65ef434bac89045afd60911b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1872a02d29a54656a14205959ee6cfb9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7695c4739a1144809ad0c82ea12bfad3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f3b44230fcdb4fc996bd316cc4bdd8a3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4ca3f5689b1a473f95041452dd3e8fe4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d8c57ffc6ba5463aabd16046fcbe41a7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "25d60a2e2ec24ab1b3737551420ac608": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "617c17d270a2472381227c064ddba078": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_796dd9b5fcb14540aa5a9ad6cc4e147d",
              "IPY_MODEL_efc5fee05c9f4675992a63d3bed2bc25",
              "IPY_MODEL_29bc3990be3d4ac1a027c506d971f59b"
            ],
            "layout": "IPY_MODEL_5c76edff32ee4700827025811fcc6b02"
          }
        },
        "796dd9b5fcb14540aa5a9ad6cc4e147d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_91639ac6ff6a4dd88e022728ff478051",
            "placeholder": "​",
            "style": "IPY_MODEL_f6980182dbf34758ae1178e0a08da54d",
            "value": "README.md: "
          }
        },
        "efc5fee05c9f4675992a63d3bed2bc25": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c7feca5eae414769aeb7fafd1a66c8e6",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_37164e6d95fd4b5c97c2f481e7d8e8bc",
            "value": 1
          }
        },
        "29bc3990be3d4ac1a027c506d971f59b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_05540166682b4db69a9651dc59c8b142",
            "placeholder": "​",
            "style": "IPY_MODEL_86880a5e7b684378b6079a87a39b1020",
            "value": " 10.5k/? [00:00&lt;00:00, 1.13MB/s]"
          }
        },
        "5c76edff32ee4700827025811fcc6b02": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "91639ac6ff6a4dd88e022728ff478051": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f6980182dbf34758ae1178e0a08da54d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c7feca5eae414769aeb7fafd1a66c8e6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "37164e6d95fd4b5c97c2f481e7d8e8bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "05540166682b4db69a9651dc59c8b142": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "86880a5e7b684378b6079a87a39b1020": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c5c287fef9c146cbb1da4111eeaae297": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c9e62369ecb648698514c16d9cbb31c2",
              "IPY_MODEL_5439c8a8570243c593437b3d295e18b1",
              "IPY_MODEL_01d945247bd04649a806c607368f2b1f"
            ],
            "layout": "IPY_MODEL_0573c3b2bbac4209be0479334f4af0d7"
          }
        },
        "c9e62369ecb648698514c16d9cbb31c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_28af72495e1a4edc8a7cbd25868545ca",
            "placeholder": "​",
            "style": "IPY_MODEL_43af3459b94049ceae59566b7fdbb0ea",
            "value": "sentence_bert_config.json: 100%"
          }
        },
        "5439c8a8570243c593437b3d295e18b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_43ec165e754b4e09891046320418fe12",
            "max": 53,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_904cf7a78cfd43cd947fd240d8eae614",
            "value": 53
          }
        },
        "01d945247bd04649a806c607368f2b1f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_856bc1f1216044f29cff035a81c6c410",
            "placeholder": "​",
            "style": "IPY_MODEL_90747b76bbd741a18c4a6f1264251934",
            "value": " 53.0/53.0 [00:00&lt;00:00, 6.90kB/s]"
          }
        },
        "0573c3b2bbac4209be0479334f4af0d7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "28af72495e1a4edc8a7cbd25868545ca": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "43af3459b94049ceae59566b7fdbb0ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "43ec165e754b4e09891046320418fe12": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "904cf7a78cfd43cd947fd240d8eae614": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "856bc1f1216044f29cff035a81c6c410": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "90747b76bbd741a18c4a6f1264251934": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8afb980d3c3946dbb21f5c6cb23c9fef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_dea9d2927507438096b358cd5f5efe9f",
              "IPY_MODEL_71efc6fc80524a0abe9d824715545b25",
              "IPY_MODEL_73e5695db20f4506b164502bc4a032ea"
            ],
            "layout": "IPY_MODEL_c7ca35b0377441c08b1656af34a4deef"
          }
        },
        "dea9d2927507438096b358cd5f5efe9f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_58ac866026474cf492fb6febbfec92d2",
            "placeholder": "​",
            "style": "IPY_MODEL_131d431d602d4ffb99012fd94d0944c5",
            "value": "config.json: 100%"
          }
        },
        "71efc6fc80524a0abe9d824715545b25": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f4cb1cb2f30942debc46edb6b4c055e3",
            "max": 612,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7c110b603c7c44669d713f6b8c3b8bbd",
            "value": 612
          }
        },
        "73e5695db20f4506b164502bc4a032ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c864923aa7584ef28cf802fa565c7dce",
            "placeholder": "​",
            "style": "IPY_MODEL_4cab48bd01684a8cac63b5fcac5cc21b",
            "value": " 612/612 [00:00&lt;00:00, 77.1kB/s]"
          }
        },
        "c7ca35b0377441c08b1656af34a4deef": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "58ac866026474cf492fb6febbfec92d2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "131d431d602d4ffb99012fd94d0944c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f4cb1cb2f30942debc46edb6b4c055e3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7c110b603c7c44669d713f6b8c3b8bbd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c864923aa7584ef28cf802fa565c7dce": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4cab48bd01684a8cac63b5fcac5cc21b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d4720bacfa7b403e8b7b750a804d9b69": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fa42d92fe8424c06a90c222700aa2f30",
              "IPY_MODEL_34cdcb87238140748f6ec290e2ffee1b",
              "IPY_MODEL_f7a67e2ecb014bbdb5e418f4d9a5f5c3"
            ],
            "layout": "IPY_MODEL_aea44c20bff040e787504e8140e98d21"
          }
        },
        "fa42d92fe8424c06a90c222700aa2f30": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b53ede5a55184d15a1cccfe7bea084dc",
            "placeholder": "​",
            "style": "IPY_MODEL_7d3feea767f644e5bc81fca23f046781",
            "value": "model.safetensors: 100%"
          }
        },
        "34cdcb87238140748f6ec290e2ffee1b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c4cb993eee254490bdeabef8d5fb2068",
            "max": 90868376,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9475c69229bf4ff28a2b9201b4e26880",
            "value": 90868376
          }
        },
        "f7a67e2ecb014bbdb5e418f4d9a5f5c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6d574b6472004461843bb0fa78bbe6e8",
            "placeholder": "​",
            "style": "IPY_MODEL_07e78b7ea7ab4228835d0117417b40f6",
            "value": " 90.9M/90.9M [00:01&lt;00:00, 83.6MB/s]"
          }
        },
        "aea44c20bff040e787504e8140e98d21": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b53ede5a55184d15a1cccfe7bea084dc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7d3feea767f644e5bc81fca23f046781": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c4cb993eee254490bdeabef8d5fb2068": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9475c69229bf4ff28a2b9201b4e26880": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6d574b6472004461843bb0fa78bbe6e8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "07e78b7ea7ab4228835d0117417b40f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "80329e814da541a2ac2cf0a0cd670243": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_67fe3978b0e341e0887dfc41b3f9a57c",
              "IPY_MODEL_8c448fca08dd4885b96b59282813fe26",
              "IPY_MODEL_5ba78fda4510496ebf0b80890a979d13"
            ],
            "layout": "IPY_MODEL_a0dd074825cc4fe4b2937df1d7db7704"
          }
        },
        "67fe3978b0e341e0887dfc41b3f9a57c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_64cf14d872fe46f5b45b7e786f62905a",
            "placeholder": "​",
            "style": "IPY_MODEL_de9b9a9b432841f6a7b16ecaba0f3a11",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "8c448fca08dd4885b96b59282813fe26": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f16850715e5846d2936bf8d19b239e9f",
            "max": 350,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5cc9000053d940d694815f4ebdb60fe7",
            "value": 350
          }
        },
        "5ba78fda4510496ebf0b80890a979d13": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9e4e033783c44425ab944c2d28bbbaea",
            "placeholder": "​",
            "style": "IPY_MODEL_94da18c3a00244b1a94e2e93b71d6f80",
            "value": " 350/350 [00:00&lt;00:00, 48.4kB/s]"
          }
        },
        "a0dd074825cc4fe4b2937df1d7db7704": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "64cf14d872fe46f5b45b7e786f62905a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "de9b9a9b432841f6a7b16ecaba0f3a11": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f16850715e5846d2936bf8d19b239e9f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5cc9000053d940d694815f4ebdb60fe7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9e4e033783c44425ab944c2d28bbbaea": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "94da18c3a00244b1a94e2e93b71d6f80": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "91adb3a2949d4f2ca968ddd883a5e760": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ad27643b4cb84b5d9ec45b46e3cc233c",
              "IPY_MODEL_3e2987a761d345f6a234e2830c8a8b12",
              "IPY_MODEL_f41236b024614d059a4e36796088ab78"
            ],
            "layout": "IPY_MODEL_94d3240ca44e4c26b6944c3c26101227"
          }
        },
        "ad27643b4cb84b5d9ec45b46e3cc233c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e9ab502c3d8e4a3e9ad279ee087ee89e",
            "placeholder": "​",
            "style": "IPY_MODEL_998a48779586445b9d69824307b822e1",
            "value": "vocab.txt: "
          }
        },
        "3e2987a761d345f6a234e2830c8a8b12": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_42b7ffd866104139b231dde94c182b6f",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_86a7edbce19c4416869e99a7a9fb7071",
            "value": 1
          }
        },
        "f41236b024614d059a4e36796088ab78": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9b893ea794074486b9026da98a6f240c",
            "placeholder": "​",
            "style": "IPY_MODEL_d8efe1d62c5440b5a370d8c75b5a9d86",
            "value": " 232k/? [00:00&lt;00:00, 2.13MB/s]"
          }
        },
        "94d3240ca44e4c26b6944c3c26101227": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e9ab502c3d8e4a3e9ad279ee087ee89e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "998a48779586445b9d69824307b822e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "42b7ffd866104139b231dde94c182b6f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "86a7edbce19c4416869e99a7a9fb7071": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9b893ea794074486b9026da98a6f240c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d8efe1d62c5440b5a370d8c75b5a9d86": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "713e810077f54b85bb45b107c139a9dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ba980f76b13d47c694fbb799c199d1ac",
              "IPY_MODEL_25fcaf1a537b48a098c61e58aaf8ce9a",
              "IPY_MODEL_6c93ca27da844a389f850c2132dbb90e"
            ],
            "layout": "IPY_MODEL_99a65fce944445abad1a2b021337896a"
          }
        },
        "ba980f76b13d47c694fbb799c199d1ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_525e38d7e3854ec19603949debe0a67a",
            "placeholder": "​",
            "style": "IPY_MODEL_211b5b6957744b94bf2d08a9f49912c0",
            "value": "tokenizer.json: "
          }
        },
        "25fcaf1a537b48a098c61e58aaf8ce9a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_39bba0202144447998b90ebe3773b7bd",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_52644a667258412bb781c7b84b203dc5",
            "value": 1
          }
        },
        "6c93ca27da844a389f850c2132dbb90e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_efc131b100d64185a4605e0eeb9c6ee9",
            "placeholder": "​",
            "style": "IPY_MODEL_2ae0374131a94a15b4b0cb7f9462dae5",
            "value": " 466k/? [00:00&lt;00:00, 6.51MB/s]"
          }
        },
        "99a65fce944445abad1a2b021337896a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "525e38d7e3854ec19603949debe0a67a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "211b5b6957744b94bf2d08a9f49912c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "39bba0202144447998b90ebe3773b7bd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "52644a667258412bb781c7b84b203dc5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "efc131b100d64185a4605e0eeb9c6ee9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2ae0374131a94a15b4b0cb7f9462dae5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cdb8652047c34782aa23043f3cd04f95": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_cc778b2898c94e3c8920eaff7c84c2c4",
              "IPY_MODEL_77614c33d2b542c6a52bc1fb2c37a75f",
              "IPY_MODEL_ba6aa618936a418599780c5df7f42b2a"
            ],
            "layout": "IPY_MODEL_b21a6fea3077415ebb885df6add1802f"
          }
        },
        "cc778b2898c94e3c8920eaff7c84c2c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a03bcb242c2644d4a39c79c9151da732",
            "placeholder": "​",
            "style": "IPY_MODEL_370e3a4342a944ad96c779ac9b4e14ef",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "77614c33d2b542c6a52bc1fb2c37a75f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_75bb1ea043474c6f9683c188017c9997",
            "max": 112,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_508e7ca51fe04f46b10ee763c41bc5ae",
            "value": 112
          }
        },
        "ba6aa618936a418599780c5df7f42b2a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bf3c25eefeb74594a0859c88f1fd0fc9",
            "placeholder": "​",
            "style": "IPY_MODEL_afef793285d0432cab056daaad036e75",
            "value": " 112/112 [00:00&lt;00:00, 14.9kB/s]"
          }
        },
        "b21a6fea3077415ebb885df6add1802f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a03bcb242c2644d4a39c79c9151da732": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "370e3a4342a944ad96c779ac9b4e14ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "75bb1ea043474c6f9683c188017c9997": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "508e7ca51fe04f46b10ee763c41bc5ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bf3c25eefeb74594a0859c88f1fd0fc9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "afef793285d0432cab056daaad036e75": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7a0b1e443d724146a81b040c7a641e99": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_87e7a117a1264132a32ac004881f9182",
              "IPY_MODEL_e78b54121be44448abc9d96cbb82de17",
              "IPY_MODEL_f9581141305f442997ade35b88150e34"
            ],
            "layout": "IPY_MODEL_53b36eb75c0d4f6b974d7cdd78bdeb28"
          }
        },
        "87e7a117a1264132a32ac004881f9182": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d720310e84ef40faabf7daf8cf23f975",
            "placeholder": "​",
            "style": "IPY_MODEL_ea3503d2741c4d0d9ce0db2402859f2c",
            "value": "config.json: 100%"
          }
        },
        "e78b54121be44448abc9d96cbb82de17": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_02355254527649368ca5d827a5a32d64",
            "max": 190,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5704b6b0ff814a27a961886d3cecd6f2",
            "value": 190
          }
        },
        "f9581141305f442997ade35b88150e34": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a8e9f410b32c46c1a8f6d0b6f3ef1946",
            "placeholder": "​",
            "style": "IPY_MODEL_b1fdd7bbbd534882a568110fc6fb489e",
            "value": " 190/190 [00:00&lt;00:00, 23.5kB/s]"
          }
        },
        "53b36eb75c0d4f6b974d7cdd78bdeb28": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d720310e84ef40faabf7daf8cf23f975": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ea3503d2741c4d0d9ce0db2402859f2c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "02355254527649368ca5d827a5a32d64": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5704b6b0ff814a27a961886d3cecd6f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a8e9f410b32c46c1a8f6d0b6f3ef1946": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b1fdd7bbbd534882a568110fc6fb489e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}